{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **In this notebook all the combinations of models, datasets, preprocessing methods done until now will be joined together. The focus will be on scalability, dinamicity and correct saving of the results.**\n","\n","\n","\n","\n","\n"],"metadata":{"id":"WZrWMJdZj9Ml"}},{"cell_type":"markdown","source":["USEFUL LINKS:\n","\n","https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel"],"metadata":{"id":"NycpltI6jw3z"}},{"cell_type":"markdown","source":["### Imports section: \n"],"metadata":{"id":"rF5TioewxTdK"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hw0MVKdRVoTq","executionInfo":{"status":"ok","timestamp":1662975156614,"user_tz":-120,"elapsed":2058,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}},"outputId":"cb77404f-743b-48ec-f7e1-027dd386cb72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n"]}],"source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/Drive')"]},{"cell_type":"code","source":["# Imports\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n","from sklearn.metrics import precision_score, recall_score, accuracy_score, balanced_accuracy_score, f1_score, matthews_corrcoef, classification_report, make_scorer\n","from sklearn.linear_model import LogisticRegression, Lasso\n","import matplotlib.pyplot as plt\n","from xlwt import Workbook\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","import os\n","from pandas_profiling import ProfileReport\n","from sklearn import svm\n","from sklearn.svm import SVC\n","from datetime import datetime\n","from sklearn.feature_selection import SelectFromModel"],"metadata":{"id":"mFaV9WnyVwo1","executionInfo":{"status":"ok","timestamp":1662975158370,"user_tz":-120,"elapsed":1760,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","!pip freeze\n","# ! pip install scikit-learn==0.24.2 # Downgrading the scikit learn library to obtain same results of previous experiments and Convergence"],"metadata":{"id":"iDpF8rN0Vyfc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Download of all datasets with different preprocessing strategies and feature spaces"],"metadata":{"id":"ay3Xy-3nxZHx"}},{"cell_type":"code","source":["# Current working directory and other paths\n","cwd = os.getcwd()\n","print(cwd)\n","!cd Drive/\n","path = cwd + \"/Drive/My Drive/magistrale/BioinformaticsProject/data/\"\n","results_path = cwd + \"/Drive/My Drive/magistrale/BioinformaticsProject/results/\"\n","\n","# Count per Million matrix\n","cpm_dataset = pd.read_csv(path+\"CPM.csv\",index_col=0) #read the main CPM dataset(67k × 719)\n","cpm_dataset = cpm_dataset.transpose() # (719 × 67k)\n","# Training and Testing datasets\n","training_ds =  pd.read_excel(path+\"train.test.xlsx\", sheet_name=\"train\")\n","testing_ds = pd.read_excel(path+\"train.test.xlsx\", sheet_name=\"test\")\n","\n","# Feature space datesets\n","base_feature_space =path+\"FEATURE_SPACES(RAW +CPM).xlsx\"\n","# List of feature space name \n","feature_space_files =[\"FEATURE_SPACE6(MAIN)\", \"FEATURE_SPACE1(PAM)\", \"FEATURE_SPACE2(PAM)\",\"FEATURE_SPACE1(LIMMA)\",\"FEATURE_SPACE2(LIMMA)\", \"FEATURE_SPACE7(pamsimilarity)\",\"FEATURE_SPACE8(limmasimilarity)\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLS8a3QiV22W","executionInfo":{"status":"ok","timestamp":1662975190657,"user_tz":-120,"elapsed":15798,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}},"outputId":"395849e7-7309-48d1-d1fd-b8d3bdbd3311"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["def extract_and_reduce_by_columns(path, sheet_name, name, nofeats_ds, preproc_strategy: str= \"none\"): \n","  \"\"\"\n","     Function to extract dataset and a specific group of its columns.\n","\n","     path: the path where to get the data values (isoforms)\n","     sheet_name: the excel sheet were to get the columns to select for the data (isoforms)\n","     nofeats_ds: the dataset without the additional columns\n","     name: 'trainingset' or 'testingset' for the excel \n","     preproc_strategy: which preprocessing strategy to apply to the ds\n","\n","  \"\"\"\n","  full_df = pd.read_excel(path, sheet_name=sheet_name) # path of subdatset \n","  full_list= full_df['isoform'].values.tolist()  #exatrct the list of isoforms names as list\n","  if preproc_strategy == 'loge':\n","    # https://stackoverflow.com/questions/49538185/purpose-of-numpy-log1p\n","    log_cpm_dataset = np.log1p(cpm_dataset)\n","    data = log_cpm_dataset[np.intersect1d(log_cpm_dataset.columns, full_list)]\n","  elif preproc_strategy == 'log2':\n","    log_cpm_dataset = np.log2(cpm_dataset + 1) # constant added to avoid reaching zero\n","    data = log_cpm_dataset[np.intersect1d(log_cpm_dataset.columns, full_list)]\n","  elif preproc_strategy == 'normperrow':\n","    # normalize per rows\n","    data = cpm_dataset[np.intersect1d(cpm_dataset.columns, full_list)]\n","    data = data.div(data.sum(axis=1), axis=0) # ----> preprocessing scaling step to try, not working\n","  elif preproc_strategy == 'none':\n","    data = cpm_dataset[np.intersect1d(cpm_dataset.columns, full_list)]  # find the mutual isoform between main datset and subdatset \n","  \n","  data.reset_index(inplace=True)\n","  data.rename(columns={ data.columns[0]: \"sample_id\" }, inplace = True)\n","\n","  x = nofeats_ds['sample_id'].values.tolist()\n","  data1= data.loc[data['sample_id'].isin(x)]\n","  result = pd.merge(data1, nofeats_ds, on='sample_id')\n","  result\n","  result.rename(columns={'sample_id.1':'subtype'}, inplace=True )\n"," \n","  # result.to_csv(name +\".csv\", index=False) # save as csv file \n","  return result"],"metadata":{"id":"VKVKnq_mWLQm","executionInfo":{"status":"ok","timestamp":1662975190658,"user_tz":-120,"elapsed":21,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":[" DATASET 1 CON FS PAM50\n"," "],"metadata":{"id":"kASP_N3D_Z9q"}},{"cell_type":"code","source":["# List of feature space name \n","feature_space_files =[\"FEATURE_SPACE6(MAIN)\", \"FEATURE_SPACE1(PAM)\", \"FEATURE_SPACE2(PAM)\",\"FEATURE_SPACE1(LIMMA)\",\"FEATURE_SPACE2(LIMMA)\", \"FEATURE_SPACE7(pamsimilarity)\",\"FEATURE_SPACE8(limmasimilarity)\"]"],"metadata":{"id":"CKDm9YMLAZJe","executionInfo":{"status":"ok","timestamp":1662975190658,"user_tz":-120,"elapsed":19,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\", 'trainingset', training_ds, 'none') \n","X_train_pam = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","Y_train_pam =train.subtype\n","print(\"X_train size:\", X_train_pam.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\",'testingset', testing_ds,'none' ) \n","X_test_pam = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_pam = test.subtype\n","print(\"X_test size:\", X_test_pam.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qOyi2GPFZvQn","executionInfo":{"status":"ok","timestamp":1662927902532,"user_tz":-120,"elapsed":16486,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"6ca7b626-29ce-471f-9cb9-6295fba1371e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train size: (550, 131)\n","X_test size: (137, 131)\n"]}]},{"cell_type":"markdown","source":["DATASET 2 CON FS LIMMA50"],"metadata":{"id":"FZIvQC6W_fHg"}},{"cell_type":"code","source":["# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\", 'trainingset', training_ds, 'none' ) \n","X_train_limma = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","Y_train_limma =train.subtype\n","print(\"X_train size:\", X_train_limma.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\",'testingset', testing_ds, 'none') \n","X_test_limma = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_limma = test.subtype\n","print(\"X_test size:\", X_test_limma.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-xuVX_FkAHjX","executionInfo":{"status":"ok","timestamp":1662928933605,"user_tz":-120,"elapsed":11724,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"fa280f1d-c257-4373-d908-d17cdebaab49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train size: (550, 557)\n","X_test size: (137, 557)\n"]}]},{"cell_type":"markdown","source":["DATASET 3 CON FS PAM50 E LOGE PREPROC\n","\n","\n"],"metadata":{"id":"7FpsrDco_i0T"}},{"cell_type":"code","source":["# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\", 'trainingset', training_ds, 'loge') \n","X_train_pam_loge = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","Y_train_pam_loge=train.subtype\n","print(\"X_train size:\", X_train_pam_loge.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\",'testingset', testing_ds,'loge' ) \n","X_test_pam_loge = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_pam_loge = test.subtype\n","print(\"X_test size:\", X_test_pam_loge.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SlmcbwTAINV","executionInfo":{"status":"ok","timestamp":1662929948193,"user_tz":-120,"elapsed":13500,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"af8f0b05-79bf-44e8-ae04-9b486e00c4ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train size: (550, 131)\n","X_test size: (137, 131)\n"]}]},{"cell_type":"markdown","source":["DATASET 4 CON FS LIMMA50 E LOGE PREPROC"],"metadata":{"id":"AdSqftj5_oDp"}},{"cell_type":"code","source":["# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\", 'trainingset', training_ds, 'loge' ) \n","X_train_limma_loge = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","Y_train_limma_loge =train.subtype\n","print(\"X_train size:\", X_train_limma_loge.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\",'testingset', testing_ds, 'loge') \n","X_test_limma_loge = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_limma_loge = test.subtype\n","print(\"X_test size:\", X_test_limma_loge.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mo128XJEAI9_","executionInfo":{"status":"ok","timestamp":1662929961257,"user_tz":-120,"elapsed":13070,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"c7611579-71ae-46fc-8928-94c4f1566a02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train size: (550, 557)\n","X_test size: (137, 557)\n"]}]},{"cell_type":"markdown","source":["DATASET 5 CON FS PAM50 E LOG2 PREPROC"],"metadata":{"id":"NceijP63_1C_"}},{"cell_type":"code","source":["# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\", 'trainingset', training_ds, 'log2') \n","X_train_pam_log2 = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","Y_train_pam_log2 =train.subtype\n","print(\"X_train size:\", X_train_pam_log2.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\",'testingset', testing_ds,'log2' ) \n","X_test_pam_log2 = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_pam_log2 = test.subtype\n","print(\"X_test size:\", X_test_pam_log2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyWlNykdAJjZ","executionInfo":{"status":"ok","timestamp":1662930746508,"user_tz":-120,"elapsed":13287,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"793d01ab-9660-48c8-cf78-362f9830b7db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train size: (550, 131)\n","X_test size: (137, 131)\n"]}]},{"cell_type":"markdown","source":["DATASET 6 CON FS LIMMA50 E LOG2 PREPROC"],"metadata":{"id":"agW5bW6s_4ja"}},{"cell_type":"code","source":["# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\", 'trainingset', training_ds, 'log2' ) \n","X_train_limma_log2 = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","Y_train_limma_log2 =train.subtype\n","print(\"X_train size:\", X_train_limma_log2.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\",'testingset', testing_ds, 'log2') \n","X_test_limma_log2 = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_limma_log2 = test.subtype\n","print(\"X_test size:\", X_test_limma_log2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nbc56NqGAKIw","executionInfo":{"status":"ok","timestamp":1662930759199,"user_tz":-120,"elapsed":12693,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"d27729ae-ec3b-45ed-e7e4-05d97cb47169"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train size: (550, 557)\n","X_test size: (137, 557)\n"]}]},{"cell_type":"markdown","source":["DATASET 7 CON FS REDUCED FROM PAM50 E LOG PREPROCESSING (choose the best between 2 and e)"],"metadata":{"id":"l0I2qr2H_8fP"}},{"cell_type":"code","source":["sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n","sel_.fit(X_train_pam_loge,Y_train_pam_loge)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jtKWfvmOD30B","executionInfo":{"status":"ok","timestamp":1662930759598,"user_tz":-120,"elapsed":421,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"db8b3668-974b-4848-c1a1-23a862b3c81f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SelectFromModel(estimator=LogisticRegression(C=1, penalty='l1',\n","                                             solver='liblinear'))"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["sel_.get_support()\n","selected_feat = X_train_pam_loge.columns[(sel_.get_support())]"],"metadata":{"id":"zaUzjJbsD3sq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('total features: {}'.format((X_train_pam_loge.shape[1])))\n","print('selected features: {}'.format(len(selected_feat)))\n","print('Percentage features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)/131*5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqYWFbAuD3jZ","executionInfo":{"status":"ok","timestamp":1662930759599,"user_tz":-120,"elapsed":8,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"29c5a02d-9e33-4a4c-8f26-58d4619f00ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total features: 131\n","selected features: 118\n","Percentage features with coefficients shrank to zero: 13.931297709923665\n"]}]},{"cell_type":"code","source":["X_train_pam_loge_sel = X_train_pam_loge[selected_feat].copy()\n","Y_train_pam_loge_sel = Y_train_pam_loge\n","\n","X_test_pam_loge_sel = X_test_pam_loge[selected_feat].copy()\n","Y_test_pam_loge_sel = Y_test_pam_loge"],"metadata":{"id":"TdEkItmBEKGw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DATASET 8 CON FS REDUCED FROM LIMMA50 E LOG PREPROCESSING (choose the best between 2 and e)"],"metadata":{"id":"5oz4_Xl5ADNx"}},{"cell_type":"code","source":["sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n","sel_.fit(X_train_limma_loge,Y_train_limma_loge)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLGJpecyALR-","executionInfo":{"status":"ok","timestamp":1662930759947,"user_tz":-120,"elapsed":351,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"aa6682ec-c3fc-4d03-dd30-51c07bcfd8cf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SelectFromModel(estimator=LogisticRegression(C=1, penalty='l1',\n","                                             solver='liblinear'))"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["sel_.get_support()\n","selected_feat = X_train_limma.columns[(sel_.get_support())]"],"metadata":{"id":"PZhWQ01wImRJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('total features: {}'.format((X_train_limma_loge.shape[1])))\n","print('selected features: {}'.format(len(selected_feat)))\n","print('Percentage features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)/557*5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-DIilh9xImK5","executionInfo":{"status":"ok","timestamp":1662930759948,"user_tz":-120,"elapsed":7,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"6f155121-3bf3-4fe2-96ca-e6292c7600ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total features: 557\n","selected features: 248\n","Percentage features with coefficients shrank to zero: 21.481149012567325\n"]}]},{"cell_type":"code","source":["X_train_limma_loge_sel = X_train_limma_loge[selected_feat].copy()\n","Y_train_limma_loge_sel = Y_train_limma_loge\n","\n","X_test_limma_loge_sel = X_test_limma_loge[selected_feat].copy()\n","Y_test_limma_loge_sel = Y_test_limma_loge"],"metadata":{"id":"rhHP4WFuImEs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DATASET 9 CON FS NEW E LOG PREPROCESSING (choose best try 2 for now) "],"metadata":{"id":"hKRISqrDAJ_H"}},{"cell_type":"markdown","source":["#### feature selection on all features"],"metadata":{"id":"u8riMKSFueaj"}},{"cell_type":"code","source":["# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE6(MAIN)\", 'trainingset', training_ds, 'loge') \n","X_train_lasso = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","samples_train = train.sample_id\n","Y_train_lasso=train.subtype\n","print(\"X_train size:\", X_train_lasso.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space,\"FEATURE_SPACE6(MAIN)\", 'testingset', testing_ds,  'loge') \n","X_test_lasso = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_lasso = test.subtype\n","print(\"X_test size:\", X_test_lasso.shape)"],"metadata":{"id":"iw_h3CWwmLwk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662975218659,"user_tz":-120,"elapsed":21171,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}},"outputId":"a50f9b4c-10dd-44b3-e6c2-b5cb15b1ff36"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train size: (550, 49740)\n","X_test size: (137, 49740)\n"]}]},{"cell_type":"code","source":["sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n","sel_.fit(X_train_lasso,Y_train_lasso)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SSxUQyYouqC2","executionInfo":{"status":"ok","timestamp":1662975229770,"user_tz":-120,"elapsed":11115,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}},"outputId":"30e786c5-68d0-4e18-a3e2-a7411d0ceda1"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SelectFromModel(estimator=LogisticRegression(C=1, penalty='l1',\n","                                             solver='liblinear'))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["sel_.get_support()\n","selected_feat = X_train_lasso.columns[(sel_.get_support())]\n","print(sel_.estimator_.coef_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2LGGfY_us2K","executionInfo":{"status":"ok","timestamp":1662975229771,"user_tz":-120,"elapsed":25,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}},"outputId":"b5463ce8-5ea8-4cc6-95bc-821a6c3602a3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"]}]},{"cell_type":"code","source":["print('total features: {}'.format((X_train_lasso.shape[1])))\n","print('selected features: {}'.format(len(selected_feat)))\n","print('coefficients shrank to zero: {}'.format(\n","      np.sum(sel_.estimator_.coef_ == 0)))\n","\n","perc_feat_selected = np.sum(sel_.estimator_.coef_ == 0)/ (49740*5)\n","print(perc_feat_selected)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPzaBOVOu1Bu","executionInfo":{"status":"ok","timestamp":1662975229772,"user_tz":-120,"elapsed":21,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}},"outputId":"67e4d814-c936-4d6f-c406-6666b79325dd"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["total features: 49740\n","selected features: 1962\n","coefficients shrank to zero: 246260\n","0.9901889827100925\n"]}]},{"cell_type":"code","source":["X_train_lasso = X_train_lasso[selected_feat].copy()\n","Y_train_lasso = Y_train_lasso\n","\n","X_test_lasso = X_test_lasso[selected_feat].copy()\n","Y_test_lasso = Y_test_lasso"],"metadata":{"id":"UlS8buXoKp2K","executionInfo":{"status":"ok","timestamp":1662975229772,"user_tz":-120,"elapsed":19,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Model training, evaluation and saving of results\n"],"metadata":{"id":"hS8speNhmNy4"}},{"cell_type":"code","source":["def write_results(results, final_path, name_file):\n","      '''\n","      Function to write results metrics and confing into a csv file with as name the current date\n","      '''\n","      if not os.path.exists(results_path+final_path):\n","        os.mkdir(results_path+final_path)\n","\n","      # datetime object containing current date and time\n","      now = datetime.now()\n","      dt_string = now.strftime(\"%d%m%Y%H%M%S\")\n","      \n","      df = pd.DataFrame(results)\n","      df.to_csv(results_path+final_path+name_file+dt_string+\".csv\")"],"metadata":{"id":"z6pLIoMgkXOZ","executionInfo":{"status":"ok","timestamp":1662975236114,"user_tz":-120,"elapsed":206,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def training_and_saving_after_cv_and_single_split(which_ds, X_train, Y_train,X_test, Y_test, scores, param_values, model):\n","\n","  C = []\n","  l1_ratio = []\n","  cv_best = []\n","  score_test_balanced_accuracy = []\n","  score_test_accuracy = []\n","  precision = []\n","  recall = []\n","  f1=[]\n","\n","  for index, score in enumerate(scores):\n","      # -------RESULTS in CROSS_VALIDATION-----------\n","      print(\"Tuning hyper-parameters for %s\" % score)\n","      # Fit and hyperparameter search\n","      selected_model = GridSearchCV(model(), param_values, scoring=score, cv=10)\n","      selected_model.fit(X_train, Y_train)\n","      # found best model and fit on training\n","      print(\"Parameter setting that gave the best results on the hold out data: \",  selected_model.best_params_)\n","      print(\"Mean cross-validated score of the best_estimator found: \",  selected_model.best_score_)\n","\n","      # save top config and score from grid search (only accuracy or balanced accuracy)\n","      # evaltype datasetdetails modelname parameters balancedaccuracy\n","      dic_result = {}\n","      dic_result['eval_type']= ['GRID SEARCH RESULTS']\n","      dic_result['dataset_details']= [which_ds]\n","      dic_result['model_name']=  [model.__name__ ]\n","      dic_result['top_parameters']= [str(selected_model.best_params_)]\n","      dic_result['name_score']= [score]\n","      dic_result['score_value'] = [selected_model.best_score_]\n","      df_result = pd.DataFrame.from_dict(dic_result)\n","      print('Grid search results: ', df_result)\n","      write_results(df_result,model.__name__ +'/', 'cv_on_'+score)\n","\n","      # use top config and trained model for evaluation on test\n","      y_true, y_pred = Y_test, selected_model.predict(X_test)\n","\n","      # save results from test\n","      # evaltype datasetdetails modelname parameters balacc accc prec rec f1\n","      dic_result = {}\n","      dic_result['eval_type']= ['TEST GRID SEARCH RESULTS']\n","      dic_result['dataset_details']= [which_ds]\n","      dic_result['model_name']=  [model.__name__ ]\n","      dic_result['top_parameters']= [str(selected_model.best_params_)]\n","      dic_result['balanced_accuracy'] = [round(balanced_accuracy_score(y_true, y_pred), 3)]\n","      dic_result['accuracy'] = [round(accuracy_score(y_true, y_pred), 3)]\n","      dic_result['precision'] = [round(precision_score(y_true, y_pred, average=\"macro\"), 3)]\n","      dic_result['recall'] = [round(recall_score(y_true, y_pred, average=\"macro\"), 3)]\n","      dic_result['f1'] = [round(f1_score(y_true, y_pred, average=\"macro\"),3)]\n","\n","      df_result = pd.DataFrame.from_dict(dic_result)\n","      print('Grid search results on test eval: ', df_result)\n","      # not saved anymore because the results are the same as creating new model and performing eval on test set\n","      # it was initiially introduced for verification\n","      # write_results(df_result,model.__name__ +'/', 'testcv_on_'+score) \n","\n","      # create new model with top convig and evaluate for verification\n","      check_model = model(**selected_model.best_params_)\n","      check_model.fit(X_train, Y_train)\n","      \n","      y_true, y_pred = Y_test, check_model.predict(X_test)\n","\n","      # save again the scores\n","      dic_result = {}\n","      dic_result['eval_type']= ['TEST GRID SEARCH RESULTS']\n","      dic_result['dataset_details']= [which_ds]\n","      dic_result['model_name']=  [model.__name__ ]\n","      dic_result['top_parameters']= [str(selected_model.best_params_)]\n","      dic_result['balanced_accuracy'] = [round(balanced_accuracy_score(y_true, y_pred), 3)]\n","      dic_result['accuracy'] = [round(accuracy_score(y_true, y_pred), 3)]\n","      dic_result['precision'] = [round(precision_score(y_true, y_pred, average=\"macro\"), 3)]\n","      dic_result['recall'] = [round(recall_score(y_true, y_pred, average=\"macro\"), 3)]\n","      dic_result['f1'] = [round(f1_score(y_true, y_pred, average=\"macro\"),3)]\n","      \n","      df_result = pd.DataFrame.from_dict(dic_result)\n","      print('Results on test eval: ', df_result)\n","      write_results(df_result,model.__name__ +'/', 'test_on_'+score)"],"metadata":{"id":"GM9h4lt8kf3L","executionInfo":{"status":"ok","timestamp":1662975236415,"user_tz":-120,"elapsed":3,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### Running section"],"metadata":{"id":"aT8xxZKCAi0l"}},{"cell_type":"code","source":["# for each dataset\n","# for each model\n","# create all parameters and other details to pass to the fun\n","# run training and saving function "],"metadata":{"id":"t73Zit9ZAmuO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Parameters definition"],"metadata":{"id":"7TTKj6F5Qe5_"}},{"cell_type":"code","source":["# Configuration of parameters and name\n","\n","#GridSearch attributes\n","# Set the parameters by cross-validation\n","#'l1_ratio':[0.5], 'solver': ['saga'], 'penalty':['elasticnet']\n","logreg_tuned_parameters = [{\n","    'multi_class':  ['ovr'],\n","    'penalty':['elasticnet'],\n","    'solver': ['saga'], \n","    'max_iter':[2000], \n","    'C':  [ 0.1, 0.01], #[10 ** i for i in range(-2,1)],\n","    'l1_ratio': [ 0.01, 0.001] #[10 ** i for i in range(-2,1)] #'l1_ratio':[0.5]}]\n","    }]\n","\n","svc_tuned_parameters = [{\n","    'kernel':['poly'], \n","    'degree': [2, 3], \n","    'gamma': [10 ** i for i in range(-3,3)],\n","    'max_iter':[1000], \n","    'C': [10 ** i for i in range(-3,3)]}]\n","\n","scores = [ \"accuracy\", \"balanced_accuracy\"]\n","\n","print(logreg_tuned_parameters)\n","print(svc_tuned_parameters)"],"metadata":{"id":"JJC2B6SJ9u-G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662975258612,"user_tz":-120,"elapsed":392,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}},"outputId":"2aaabf96-ab30-494c-a515-0138489d5b5e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'multi_class': ['ovr'], 'penalty': ['elasticnet'], 'solver': ['saga'], 'max_iter': [2000], 'C': [0.1, 0.01], 'l1_ratio': [0.01, 0.001]}]\n","[{'kernel': ['poly'], 'degree': [2, 3], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100], 'max_iter': [1000], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n"]}]},{"cell_type":"markdown","source":["dataset 1 with fs pam50"],"metadata":{"id":"KZOJmt1FQtng"}},{"cell_type":"code","source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('pam_fs', X_train_pam, Y_train_pam, X_test_pam, Y_test_pam, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('pam_fs', X_train_pam, Y_train_pam, X_test_pam, Y_test_pam, scores, svc_tuned_parameters, SVC)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uod6Beh-RwYC","executionInfo":{"status":"ok","timestamp":1662928906174,"user_tz":-120,"elapsed":991709,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"b0ff8768-af3c-4a76-acea-49bfb7fc9b3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.8454545454545455\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS          pam_fs  LogisticRegression   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...   accuracy     0.845455  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS          pam_fs  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.685   \n","\n","   accuracy  precision  recall     f1  \n","0     0.825      0.837   0.685  0.701  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS          pam_fs  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.685   \n","\n","   accuracy  precision  recall     f1  \n","0     0.825      0.837   0.685  0.701  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.6903410293410294\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS          pam_fs  LogisticRegression   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...  balanced_accuracy   \n","\n","   score_value  \n","0     0.690341  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS          pam_fs  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.685   \n","\n","   accuracy  precision  recall     f1  \n","0     0.825      0.837   0.685  0.701  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS          pam_fs  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.685   \n","\n","   accuracy  precision  recall     f1  \n","0     0.825      0.837   0.685  0.701  \n","Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 2, 'gamma': 100, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8163636363636364\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS          pam_fs        SVC   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.001, 'degree': 2, 'gamma': 100, 'kerne...   accuracy     0.816364  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS          pam_fs        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 100, 'kerne...              0.703   \n","\n","   accuracy  precision  recall     f1  \n","0     0.737      0.638   0.703  0.656  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS          pam_fs        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 100, 'kerne...              0.703   \n","\n","   accuracy  precision  recall     f1  \n","0     0.737      0.638   0.703  0.656  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 2, 'gamma': 100, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.7838417508417509\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS          pam_fs        SVC   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 100, 'kerne...  balanced_accuracy   \n","\n","   score_value  \n","0     0.783842  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS          pam_fs        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 100, 'kerne...              0.703   \n","\n","   accuracy  precision  recall     f1  \n","0     0.737      0.638   0.703  0.656  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS          pam_fs        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 100, 'kerne...              0.703   \n","\n","   accuracy  precision  recall     f1  \n","0     0.737      0.638   0.703  0.656  \n"]}]},{"cell_type":"markdown","source":["dataset 2 with fs limma50"],"metadata":{"id":"jxh1TZjRRAah"}},{"cell_type":"code","source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('limma_fs', X_train_limma, Y_train_limma, X_test_limma, Y_test_limma, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('limma_fs', X_train_limma, Y_train_limma, X_test_limma, Y_test_limma, scores, svc_tuned_parameters, SVC)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"B2IJxv7TR9Cm","executionInfo":{"status":"error","timestamp":1662929921997,"user_tz":-120,"elapsed":988418,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"outputId":"2eea5fcc-3272-4cd3-b1fd-2ec91a9bbbd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-b8d66a21c61e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# EVALUATION with LOGISTIC REGRESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_and_saving_after_cv_and_single_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'limma_fs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_limma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_limma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_limma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_limma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogreg_tuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# EVALUATION with SVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtraining_and_saving_after_cv_and_single_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'limma_fs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_limma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_limma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_limma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_limma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc_tuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-5dc3254700f4>\u001b[0m in \u001b[0;36mtraining_and_saving_after_cv_and_single_split\u001b[0;34m(which_ds, X_train, Y_train, X_test, Y_test, scores, param_values, model)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;31m# Fit and hyperparameter search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mselected_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mselected_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;31m# found best model and fit on training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parameter setting that gave the best results on the hold out data: \"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mselected_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1414\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1416\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    800\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 is_saga=(solver == 'saga'))\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    323\u001b[0m                             \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                             \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                             verbose)\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["dataset 3 with fs pam50 and loge preprocessing"],"metadata":{"id":"5DGtf1JsREFE"}},{"cell_type":"code","source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('pam_fs_loge', X_train_pam_loge, Y_train_pam_loge, X_test_pam_loge, Y_test_pam_loge, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('pam_fs_loge', X_train_pam_loge, Y_train_pam_loge, X_test_pam_loge, Y_test_pam_loge, scores, svc_tuned_parameters, SVC)"],"metadata":{"id":"_i31qIc-SFz4","executionInfo":{"status":"ok","timestamp":1662930098513,"user_tz":-120,"elapsed":137264,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"adc860c7-e23d-4081-843a-61b99931a725"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.01, 'l1_ratio': 0.01, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.8690909090909091\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS     pam_fs_loge  LogisticRegression   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.01, 'l1_ratio': 0.01, 'max_iter': 2000...   accuracy     0.869091  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_loge  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'l1_ratio': 0.01, 'max_iter': 2000...              0.609   \n","\n","   accuracy  precision  recall     f1  \n","0     0.825      0.627   0.609  0.613  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_loge  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'l1_ratio': 0.01, 'max_iter': 2000...              0.609   \n","\n","   accuracy  precision  recall     f1  \n","0     0.825      0.627   0.609  0.613  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.714030303030303\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS     pam_fs_loge  LogisticRegression   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...  balanced_accuracy   \n","\n","   score_value  \n","0      0.71403  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_loge  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.635   \n","\n","   accuracy  precision  recall    f1  \n","0     0.839      0.627   0.635  0.63  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_loge  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.635   \n","\n","   accuracy  precision  recall    f1  \n","0     0.839      0.627   0.635  0.63  \n","Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8836363636363636\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS     pam_fs_loge        SVC   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...   accuracy     0.883636  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_loge        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...              0.809   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861      0.787   0.809  0.797  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_loge        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...              0.809   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861      0.787   0.809  0.797  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.01, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8319206349206348\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS     pam_fs_loge        SVC   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.01, 'degree': 3, 'gamma': 0.01, 'kerne...  balanced_accuracy   \n","\n","   score_value  \n","0     0.831921  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_loge        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'degree': 3, 'gamma': 0.01, 'kerne...              0.815   \n","\n","   accuracy  precision  recall     f1  \n","0     0.876      0.819   0.815  0.815  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_loge        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'degree': 3, 'gamma': 0.01, 'kerne...              0.815   \n","\n","   accuracy  precision  recall     f1  \n","0     0.876      0.819   0.815  0.815  \n"]}]},{"cell_type":"markdown","source":["dataset 4 with fs limma50 and loge preprocessing"],"metadata":{"id":"5pRSP59wRKaz"}},{"cell_type":"code","source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('limma_fs_loge', X_train_limma_loge, Y_train_limma_loge, X_test_limma_loge, Y_test_limma_loge, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('limma_fs_loge', X_train_limma_loge, Y_train_limma_loge, X_test_limma_loge, Y_test_limma_loge, scores, svc_tuned_parameters, SVC)"],"metadata":{"id":"RMUwDPEMSOcU","executionInfo":{"status":"ok","timestamp":1662930721389,"user_tz":-120,"elapsed":622903,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fbfdb5f9-76a1-4963-a9df-69cecdae223b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.8727272727272728\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS   limma_fs_loge  LogisticRegression   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...   accuracy     0.872727  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_loge  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.744   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861        0.8   0.744  0.761  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_loge  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.744   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861        0.8   0.744  0.761  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.7795468975468975\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS   limma_fs_loge  LogisticRegression   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...  balanced_accuracy   \n","\n","   score_value  \n","0     0.779547  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_loge  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.744   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861        0.8   0.744  0.761  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_loge  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.744   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861        0.8   0.744  0.761  \n","Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8927272727272726\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS   limma_fs_loge        SVC   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kerne...   accuracy     0.892727  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_loge        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kerne...              0.782   \n","\n","   accuracy  precision  recall     f1  \n","0     0.869      0.814   0.782  0.792  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_loge        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kerne...              0.782   \n","\n","   accuracy  precision  recall     f1  \n","0     0.869      0.814   0.782  0.792  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8405921115921118\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS   limma_fs_loge        SVC   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.001, 'degree': 3, 'gamma': 0.01, 'kern...  balanced_accuracy   \n","\n","   score_value  \n","0     0.840592  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_loge        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 3, 'gamma': 0.01, 'kern...              0.779   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861      0.809   0.779  0.788  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_loge        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 3, 'gamma': 0.01, 'kern...              0.779   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861      0.809   0.779  0.788  \n"]}]},{"cell_type":"markdown","source":["dataset 5 with fs pam50 and log2 preprocessing"],"metadata":{"id":"W80lqJ29RNj6"}},{"cell_type":"code","source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('pam_fs_log2', X_train_pam_log2, Y_train_pam_log2, X_test_pam_log2, Y_test_pam_log2, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('pam_fs_log2', X_train_pam_log2, Y_train_pam_log2, X_test_pam_log2, Y_test_pam_log2, scores, svc_tuned_parameters, SVC)"],"metadata":{"id":"Sbu6NgA5SngU","executionInfo":{"status":"ok","timestamp":1662931282370,"user_tz":-120,"elapsed":145836,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0d401732-e328-4fe2-aa87-086b0c206aa8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.01, 'l1_ratio': 0.01, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.8781818181818182\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS     pam_fs_log2  LogisticRegression   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.01, 'l1_ratio': 0.01, 'max_iter': 2000...   accuracy     0.878182  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_log2  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'l1_ratio': 0.01, 'max_iter': 2000...              0.609   \n","\n","   accuracy  precision  recall     f1  \n","0     0.825      0.615   0.609  0.609  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_log2  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'l1_ratio': 0.01, 'max_iter': 2000...              0.609   \n","\n","   accuracy  precision  recall     f1  \n","0     0.825      0.615   0.609  0.609  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.7355416065416066\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS     pam_fs_log2  LogisticRegression   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...  balanced_accuracy   \n","\n","   score_value  \n","0     0.735542  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_log2  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.668   \n","\n","   accuracy  precision  recall    f1  \n","0     0.847      0.833   0.668  0.69  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_log2  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.668   \n","\n","   accuracy  precision  recall    f1  \n","0     0.847      0.833   0.668  0.69  \n","Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8854545454545454\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS     pam_fs_log2        SVC   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kerne...   accuracy     0.885455  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_log2        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kerne...              0.793   \n","\n","   accuracy  precision  recall     f1  \n","0     0.869      0.845   0.793  0.812  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_log2        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kerne...              0.793   \n","\n","   accuracy  precision  recall     f1  \n","0     0.869      0.845   0.793  0.812  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8321866281866281\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS     pam_fs_log2        SVC   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...  balanced_accuracy   \n","\n","   score_value  \n","0     0.832187  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_log2        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...              0.775   \n","\n","   accuracy  precision  recall     f1  \n","0     0.839      0.759   0.775  0.763  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS     pam_fs_log2        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...              0.775   \n","\n","   accuracy  precision  recall     f1  \n","0     0.839      0.759   0.775  0.763  \n"]}]},{"cell_type":"markdown","source":["dataset 6 with fs limma50 and log2 preprocessing"],"metadata":{"id":"FJaN3i-vRPpf"}},{"cell_type":"code","source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('limma_fs_log2', X_train_limma_log2, Y_train_limma_log2, X_test_limma_log2, Y_test_limma_log2, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('limma_fs_log2', X_train_limma_log2, Y_train_limma_log2, X_test_limma_log2, Y_test_limma_log2, scores, svc_tuned_parameters, SVC)"],"metadata":{"id":"B4CQks0HSaxv","executionInfo":{"status":"ok","timestamp":1662932139368,"user_tz":-120,"elapsed":857008,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"16d38457-37f5-452f-a3a0-753cff2e7ab1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.01, 'l1_ratio': 0.001, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.8727272727272728\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS   limma_fs_log2  LogisticRegression   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.01, 'l1_ratio': 0.001, 'max_iter': 200...   accuracy     0.872727  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_log2  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'l1_ratio': 0.001, 'max_iter': 200...              0.729   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861        0.8   0.729  0.752  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_log2  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'l1_ratio': 0.001, 'max_iter': 200...              0.729   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861        0.8   0.729  0.752  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.7786810966810968\n","Grid search results:               eval_type dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS   limma_fs_log2  LogisticRegression   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...  balanced_accuracy   \n","\n","   score_value  \n","0     0.778681  \n","Grid search results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_log2  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.741   \n","\n","   accuracy  precision  recall     f1  \n","0     0.854      0.794   0.741  0.756  \n","Results on test eval:                    eval_type dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_log2  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.741   \n","\n","   accuracy  precision  recall     f1  \n","0     0.854      0.794   0.741  0.756  \n","Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.01, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8909090909090909\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS   limma_fs_log2        SVC   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.01, 'degree': 3, 'gamma': 0.001, 'kern...   accuracy     0.890909  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_log2        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'degree': 3, 'gamma': 0.001, 'kern...              0.759   \n","\n","   accuracy  precision  recall    f1  \n","0     0.861      0.804   0.759  0.77  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_log2        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'degree': 3, 'gamma': 0.001, 'kern...              0.759   \n","\n","   accuracy  precision  recall    f1  \n","0     0.861      0.804   0.759  0.77  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8413063973063973\n","Grid search results:               eval_type dataset_details model_name  \\\n","0  GRID SEARCH RESULTS   limma_fs_log2        SVC   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...  balanced_accuracy   \n","\n","   score_value  \n","0     0.841306  \n","Grid search results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_log2        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...              0.779   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861      0.809   0.779  0.788  \n","Results on test eval:                    eval_type dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS   limma_fs_log2        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...              0.779   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861      0.809   0.779  0.788  \n"]}]},{"cell_type":"markdown","source":["DATASET 7 CON FS REDUCED FROM PAM50 E LOG PREPROCESSING (choose the best between 2 and e)\n","\n"],"metadata":{"id":"f69mEPIFRYoI"}},{"cell_type":"code","source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('pam_fs_loge_sel', X_train_pam_loge_sel, Y_train_pam_loge_sel, X_test_pam_loge_sel, Y_test_pam_loge_sel, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('pam_fs_loge_sel', X_train_pam_loge_sel, Y_train_pam_loge_sel, X_test_pam_loge_sel, Y_test_pam_loge_sel, scores, svc_tuned_parameters, SVC)"],"metadata":{"id":"JOm1HG0DSs9x","executionInfo":{"status":"ok","timestamp":1662932273696,"user_tz":-120,"elapsed":134339,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a64d6fd9-1fca-4fe1-d9b2-721b47ed766b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.01, 'l1_ratio': 0.001, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.8690909090909089\n","Grid search results:               eval_type  dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS  pam_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.01, 'l1_ratio': 0.001, 'max_iter': 200...   accuracy     0.869091  \n","Grid search results on test eval:                    eval_type  dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  pam_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'l1_ratio': 0.001, 'max_iter': 200...              0.612   \n","\n","   accuracy  precision  recall     f1  \n","0     0.832      0.633   0.612  0.617  \n","Results on test eval:                    eval_type  dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  pam_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.01, 'l1_ratio': 0.001, 'max_iter': 200...              0.612   \n","\n","   accuracy  precision  recall     f1  \n","0     0.832      0.633   0.612  0.617  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.7197445887445888\n","Grid search results:               eval_type  dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS  pam_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...  balanced_accuracy   \n","\n","   score_value  \n","0     0.719745  \n","Grid search results on test eval:                    eval_type  dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  pam_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.656   \n","\n","   accuracy  precision  recall     f1  \n","0     0.854      0.657   0.656  0.655  \n","Results on test eval:                    eval_type  dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  pam_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.656   \n","\n","   accuracy  precision  recall     f1  \n","0     0.854      0.657   0.656  0.655  \n","Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8818181818181818\n","Grid search results:               eval_type  dataset_details model_name  \\\n","0  GRID SEARCH RESULTS  pam_fs_loge_sel        SVC   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...   accuracy     0.881818  \n","Grid search results on test eval:                    eval_type  dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  pam_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...               0.79   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861      0.783    0.79  0.786  \n","Results on test eval:                    eval_type  dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  pam_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...               0.79   \n","\n","   accuracy  precision  recall     f1  \n","0     0.861      0.783    0.79  0.786  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8270986050986051\n","Grid search results:               eval_type  dataset_details model_name  \\\n","0  GRID SEARCH RESULTS  pam_fs_loge_sel        SVC   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kerne...  balanced_accuracy   \n","\n","   score_value  \n","0     0.827099  \n","Grid search results on test eval:                    eval_type  dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  pam_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kerne...              0.778   \n","\n","   accuracy  precision  recall     f1  \n","0     0.832      0.763   0.778  0.768  \n","Results on test eval:                    eval_type  dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  pam_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kerne...              0.778   \n","\n","   accuracy  precision  recall     f1  \n","0     0.832      0.763   0.778  0.768  \n"]}]},{"cell_type":"markdown","source":["DATASET 8 CON FS REDUCED FROM LIMMA50 E LOG PREPROCESSING (choose the best between 2 and e)"],"metadata":{"id":"yxv981xjRc6M"}},{"cell_type":"code","source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('limma_fs_loge_sel', X_train_limma_loge_sel, Y_train_limma_loge_sel, X_test_limma_loge_sel, Y_test_limma_loge_sel, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('limma_fs_loge_sel', X_train_limma_loge_sel, Y_train_limma_loge_sel, X_test_limma_loge_sel, Y_test_limma_loge_sel, scores, svc_tuned_parameters, SVC)"],"metadata":{"id":"2KpvI_uoStrS","executionInfo":{"status":"ok","timestamp":1662932493447,"user_tz":-120,"elapsed":219770,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2a8c4d8-2826-40fb-bfd1-ef94c6c5d62b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.890909090909091\n","Grid search results:               eval_type    dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS  limma_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...   accuracy     0.890909  \n","Grid search results on test eval:                    eval_type    dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  limma_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.768   \n","\n","   accuracy  precision  recall     f1  \n","0     0.883      0.831   0.768  0.788  \n","Results on test eval:                    eval_type    dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  limma_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.768   \n","\n","   accuracy  precision  recall     f1  \n","0     0.883      0.831   0.768  0.788  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.7971443001443002\n","Grid search results:               eval_type    dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS  limma_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...  balanced_accuracy   \n","\n","   score_value  \n","0     0.797144  \n","Grid search results on test eval:                    eval_type    dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  limma_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.768   \n","\n","   accuracy  precision  recall     f1  \n","0     0.883      0.831   0.768  0.788  \n","Results on test eval:                    eval_type    dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  limma_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.01, 'max_iter': 2000,...              0.768   \n","\n","   accuracy  precision  recall     f1  \n","0     0.883      0.831   0.768  0.788  \n","Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.9090909090909092\n","Grid search results:               eval_type    dataset_details model_name  \\\n","0  GRID SEARCH RESULTS  limma_fs_loge_sel        SVC   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...   accuracy     0.909091  \n","Grid search results on test eval:                    eval_type    dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  limma_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...              0.776   \n","\n","   accuracy  precision  recall     f1  \n","0     0.854      0.803   0.776  0.782  \n","Results on test eval:                    eval_type    dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  limma_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.1, 'kerne...              0.776   \n","\n","   accuracy  precision  recall     f1  \n","0     0.854      0.803   0.776  0.782  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.8799547859547859\n","Grid search results:               eval_type    dataset_details model_name  \\\n","0  GRID SEARCH RESULTS  limma_fs_loge_sel        SVC   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kerne...  balanced_accuracy   \n","\n","   score_value  \n","0     0.879955  \n","Grid search results on test eval:                    eval_type    dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  limma_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kerne...              0.773   \n","\n","   accuracy  precision  recall     f1  \n","0     0.847      0.774   0.773  0.771  \n","Results on test eval:                    eval_type    dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  limma_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 3, 'gamma': 0.1, 'kerne...              0.773   \n","\n","   accuracy  precision  recall     f1  \n","0     0.847      0.774   0.773  0.771  \n"]}]},{"cell_type":"markdown","source":["DATASET 9 CON FS NEW E LOG PREPROCESSING (choose best try e for now)"],"metadata":{"id":"eghtWH-YRht3"}},{"cell_type":"code","source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('lasso_fs_loge_sel', X_train_lasso, Y_train_lasso, X_test_lasso, Y_test_lasso, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('lasso_fs_loge_sel', X_train_lasso, Y_train_lasso, X_test_lasso, Y_test_lasso, scores, svc_tuned_parameters, SVC)"],"metadata":{"id":"S-vSuXT-9d0T","executionInfo":{"status":"ok","timestamp":1662980506323,"user_tz":-120,"elapsed":5241596,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"86db37ce-0ba7-499f-90d0-a8a0cc474c1b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.9527272727272725\n","Grid search results:               eval_type    dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS  lasso_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...   accuracy     0.952727  \n","Grid search results on test eval:                    eval_type    dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.704   \n","\n","   accuracy  precision  recall     f1  \n","0     0.876      0.885   0.704  0.731  \n","Results on test eval:                    eval_type    dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.704   \n","\n","   accuracy  precision  recall     f1  \n","0     0.876      0.885   0.704  0.731  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000, 'multi_class': 'ovr', 'penalty': 'elasticnet', 'solver': 'saga'}\n","Mean cross-validated score of the best_estimator found:  0.860032708032708\n","Grid search results:               eval_type    dataset_details          model_name  \\\n","0  GRID SEARCH RESULTS  lasso_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...  balanced_accuracy   \n","\n","   score_value  \n","0     0.860033  \n","Grid search results on test eval:                    eval_type    dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.704   \n","\n","   accuracy  precision  recall     f1  \n","0     0.876      0.885   0.704  0.731  \n","Results on test eval:                    eval_type    dataset_details          model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel  LogisticRegression   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.1, 'l1_ratio': 0.001, 'max_iter': 2000...              0.704   \n","\n","   accuracy  precision  recall     f1  \n","0     0.876      0.885   0.704  0.731  \n","Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.958181818181818\n","Grid search results:               eval_type    dataset_details model_name  \\\n","0  GRID SEARCH RESULTS  lasso_fs_loge_sel        SVC   \n","\n","                                      top_parameters name_score  score_value  \n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kern...   accuracy     0.958182  \n","Grid search results on test eval:                    eval_type    dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kern...              0.788   \n","\n","   accuracy  precision  recall     f1  \n","0     0.869      0.852   0.788  0.813  \n","Results on test eval:                    eval_type    dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kern...              0.788   \n","\n","   accuracy  precision  recall     f1  \n","0     0.869      0.852   0.788  0.813  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kernel': 'poly', 'max_iter': 1000}\n","Mean cross-validated score of the best_estimator found:  0.903954785954786\n","Grid search results:               eval_type    dataset_details model_name  \\\n","0  GRID SEARCH RESULTS  lasso_fs_loge_sel        SVC   \n","\n","                                      top_parameters         name_score  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kern...  balanced_accuracy   \n","\n","   score_value  \n","0     0.903955  \n","Grid search results on test eval:                    eval_type    dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kern...              0.788   \n","\n","   accuracy  precision  recall     f1  \n","0     0.869      0.852   0.788  0.813  \n","Results on test eval:                    eval_type    dataset_details model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel        SVC   \n","\n","                                      top_parameters  balanced_accuracy  \\\n","0  {'C': 0.001, 'degree': 2, 'gamma': 0.01, 'kern...              0.788   \n","\n","   accuracy  precision  recall     f1  \n","0     0.869      0.852   0.788  0.813  \n"]}]},{"cell_type":"markdown","source":["### Random Forest Classifier exploration"],"metadata":{"id":"KixnzBjpWpdr"}},{"cell_type":"code","source":["# EVALUATION with RandomForrest\n","from sklearn.ensemble import RandomForestClassifier\n","rf_values=logreg_tuned_parameters = [{\n","    }]\n","\n","training_and_saving_after_cv_and_single_split('lasso_fs_loge_sel', X_train_lasso, Y_train_lasso, X_test_lasso, Y_test_lasso, scores, rf_values,model=RandomForestClassifier)"],"metadata":{"id":"mt73tc7fFOGx","executionInfo":{"status":"ok","timestamp":1662980756861,"user_tz":-120,"elapsed":31466,"user":{"displayName":"arianna galzerano","userId":"01686885889235545991"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c66a52c-4b7f-4ab1-a38b-41ed578edb3e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for accuracy\n","Parameter setting that gave the best results on the hold out data:  {}\n","Mean cross-validated score of the best_estimator found:  0.8818181818181818\n","Grid search results:               eval_type    dataset_details              model_name  \\\n","0  GRID SEARCH RESULTS  lasso_fs_loge_sel  RandomForestClassifier   \n","\n","  top_parameters name_score  score_value  \n","0             {}   accuracy     0.881818  \n","Grid search results on test eval:                    eval_type    dataset_details              model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel  RandomForestClassifier   \n","\n","  top_parameters  balanced_accuracy  accuracy  precision  recall     f1  \n","0             {}              0.658     0.876      0.707   0.658  0.671  \n","Results on test eval:                    eval_type    dataset_details              model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel  RandomForestClassifier   \n","\n","  top_parameters  balanced_accuracy  accuracy  precision  recall     f1  \n","0             {}              0.704     0.876      0.904   0.704  0.737  \n","Tuning hyper-parameters for balanced_accuracy\n","Parameter setting that gave the best results on the hold out data:  {}\n","Mean cross-validated score of the best_estimator found:  0.7418374218374219\n","Grid search results:               eval_type    dataset_details              model_name  \\\n","0  GRID SEARCH RESULTS  lasso_fs_loge_sel  RandomForestClassifier   \n","\n","  top_parameters         name_score  score_value  \n","0             {}  balanced_accuracy     0.741837  \n","Grid search results on test eval:                    eval_type    dataset_details              model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel  RandomForestClassifier   \n","\n","  top_parameters  balanced_accuracy  accuracy  precision  recall     f1  \n","0             {}              0.707     0.869      0.898   0.707  0.757  \n","Results on test eval:                    eval_type    dataset_details              model_name  \\\n","0  TEST GRID SEARCH RESULTS  lasso_fs_loge_sel  RandomForestClassifier   \n","\n","  top_parameters  balanced_accuracy  accuracy  precision  recall     f1  \n","0             {}              0.715     0.876      0.898   0.715  0.761  \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oY-xCrOnoJ0B"},"execution_count":null,"outputs":[]}]}