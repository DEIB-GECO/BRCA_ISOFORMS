{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZrWMJdZj9Ml"
      },
      "source": [
        "## **In this notebook all the combinations of models, datasets, preprocessing methods done until now will be joined together. The focus will be on scalability, dinamicity and correct saving of the results.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NycpltI6jw3z"
      },
      "source": [
        "USEFUL LINKS:\n",
        "\n",
        "https://towardsdatascience.com/feature-selection-using-regularisation-a3678b71e499\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF5TioewxTdK"
      },
      "source": [
        "### Imports section: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw0MVKdRVoTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01cbf5e9-12d9-4da4-9088-2bc5d7ebc4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment if needed: libraries to install on google colab\n",
        "# ! pip install mrmr_selection\n",
        "# ! pip install scikit-learn==0.24.2 # Downgrading the scikit learn library to obtain same results of previous experiments and Convergence"
      ],
      "metadata": {
        "id": "zdt0AYcVbPfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFaV9WnyVwo1"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, balanced_accuracy_score, f1_score, matthews_corrcoef, classification_report, make_scorer\n",
        "from sklearn.linear_model import LogisticRegression, Lasso\n",
        "import matplotlib.pyplot as plt\n",
        "from xlwt import Workbook\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import os\n",
        "from pandas_profiling import ProfileReport\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from datetime import datetime\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import mrmr\n",
        "from mrmr import mrmr_classif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDpF8rN0Vyfc"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip freeze | grep scikit # check scikit-learn version for conversion in grid search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUQex00RgYSB",
        "outputId": "2c4ad035-a906-4b0b-a72f-36ecdc1a42a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-image==0.18.3\n",
            "scikit-learn==0.24.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay3Xy-3nxZHx"
      },
      "source": [
        "### Download of all datasets with different preprocessing strategies and feature spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLS8a3QiV22W",
        "outputId": "30457734-f7ad-45bf-fb0e-dce897b29dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Current working directory and other paths\n",
        "cwd = os.getcwd()\n",
        "print(cwd)\n",
        "!cd Drive/\n",
        "path = cwd + \"/Drive/My Drive/magistrale/BioinformaticsProject/data/\"\n",
        "results_path = cwd + \"/Drive/My Drive/magistrale/BioinformaticsProject/results/\"\n",
        "\n",
        "# Count per Million matrix\n",
        "cpm_dataset = pd.read_csv(path+\"CPM.csv\",index_col=0) #read the main CPM dataset(67k × 719)\n",
        "cpm_dataset = cpm_dataset.transpose() # (719 × 67k)\n",
        "# Training and Testing datasets\n",
        "training_ds =  pd.read_excel(path+\"train_test_new.xlsx\", sheet_name=\"train_new\")\n",
        "testing_ds = pd.read_excel(path+\"train_test_new.xlsx\", sheet_name=\"test_new\")\n",
        "\n",
        "# Feature space datesets\n",
        "base_feature_space =path+\"FEATURE_SPACES(RAW +CPM).xlsx\"\n",
        "# List of feature space name \n",
        "feature_space_files =[\"FEATURE_SPACE6(MAIN)\", \"FEATURE_SPACE1(PAM)\", \"FEATURE_SPACE2(PAM)\",\"FEATURE_SPACE1(LIMMA)\",\"FEATURE_SPACE2(LIMMA)\", \"FEATURE_SPACE7(pamsimilarity)\",\"FEATURE_SPACE8(limmasimilarity)\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Additional step: Selecting only the samples that appear also in the gene expression dataset for a fair comparison\n",
        "\n",
        "*This cell was commented after the process of selection and moving 10 samples from train to test to keep a 30-70 split.*"
      ],
      "metadata": {
        "id": "lMWyZ2xx1rSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''training_ds_pre = training_ds\n",
        "testing_ds_pre = testing_ds\n",
        "training_ds_pre['sample_label'].unique()\n",
        "print('Len train and test befor removal: ', training_ds_pre.shape, testing_ds_pre.shape)\n",
        "values = training_ds_pre['sample_label'].unique()\n",
        "for val in values:\n",
        "  print(val+' class : ', len(training_ds_pre[training_ds_pre['sample_label']== val])/550)\n",
        "\n",
        "print('\\n')\n",
        "for val in values:\n",
        "  print(val+' class : ', len(testing_ds_pre[testing_ds_pre['sample_label']== val])/137)\n",
        "\n",
        "full_ds = pd.concat([training_ds_pre, testing_ds_pre], ignore_index=True)\n",
        "print('Full samples len with isoform expression data', full_ds.shape)\n",
        "\n",
        "gene_ds =  pd.read_csv(path+ 'gene_expression_data_and_metadata'+'/'+ '817_Patients_with_Subtype_from_TCGA_BRCA_hg19.csv', sep=';')\n",
        "print('Len samples with gene expression features: ', len(gene_ds))\n",
        "print('Samples with gene expression data: \\n\\n', gene_ds.iloc[:,0], '\\n')\n",
        "\n",
        "samples_in_common = np.intersect1d(full_ds.iloc[:,0],gene_ds.iloc[:,0])\n",
        "\n",
        "training_ds = training_ds_pre[training_ds_pre.sample_id.isin(samples_in_common)]\n",
        "testing_ds = testing_ds_pre[testing_ds_pre.sample_id.isin(samples_in_common)]\n",
        "\n",
        "\n",
        "f\"Training df only common len: {training_ds.shape}, testing df only common len: {testing_ds.shape} \"\n",
        "\n",
        "print('Len train and test befor removal: ', training_ds.shape, testing_ds.shape)\n",
        "values = training_ds['sample_id.1'].unique()\n",
        "for val in values:\n",
        "  print(val+' class : ', len(training_ds[training_ds['sample_id.1']== val])/403, len(training_ds[training_ds['sample_id.1']== val]))\n",
        "\n",
        "print('\\n')\n",
        "for val in values:\n",
        "  print(val+' class : ', len(testing_ds[testing_ds['sample_id.1']== val])/134, len(testing_ds[testing_ds['sample_id.1']== val]))\n",
        "\n",
        "with pd.ExcelWriter(path+\"train_test_new.xlsx\",engine='openpyxl', mode='a') as writer: \n",
        "  training_ds.to_excel( writer, sheet_name=\"train_new\", index=False)\n",
        "  testing_ds.to_excel(writer, sheet_name=\"test_new\", index=False)'''"
      ],
      "metadata": {
        "id": "I8zUb8L8_g0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continue with extraction of data"
      ],
      "metadata": {
        "id": "li-MkXN9SrZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKVKnq_mWLQm"
      },
      "outputs": [],
      "source": [
        "def extract_and_reduce_by_columns(path, sheet_name, name, nofeats_ds, preproc_strategy: str= \"none\"): \n",
        "  \"\"\"\n",
        "     Function to extract dataset and a specific group of its columns.\n",
        "\n",
        "     path: the path where to get the data values (isoforms)\n",
        "     sheet_name: the excel sheet were to get the columns to select for the data (isoforms)\n",
        "     nofeats_ds: the dataset without the additional columns\n",
        "     name: 'trainingset' or 'testingset' for the excel \n",
        "     preproc_strategy: which preprocessing strategy to apply to the ds\n",
        "\n",
        "  \"\"\"\n",
        "  full_df = pd.read_excel(path, sheet_name=sheet_name) # path of subdatset \n",
        "  full_list= full_df['isoform'].values.tolist()  #exatrct the list of isoforms names as list\n",
        "  if preproc_strategy == 'loge':\n",
        "    # https://stackoverflow.com/questions/49538185/purpose-of-numpy-log1p\n",
        "    log_cpm_dataset = np.log1p(cpm_dataset)\n",
        "    data = log_cpm_dataset[np.intersect1d(log_cpm_dataset.columns, full_list)]\n",
        "  elif preproc_strategy == 'log2':\n",
        "    log_cpm_dataset = np.log2(cpm_dataset + 1) # constant added to avoid reaching zero\n",
        "    data = log_cpm_dataset[np.intersect1d(log_cpm_dataset.columns, full_list)]\n",
        "  elif preproc_strategy == 'normperrow':\n",
        "    # normalize per rows\n",
        "    data = cpm_dataset[np.intersect1d(cpm_dataset.columns, full_list)]\n",
        "    data = data.div(data.sum(axis=1), axis=0) # ----> preprocessing scaling step to try, not working\n",
        "  elif preproc_strategy == 'none':\n",
        "    data = cpm_dataset[np.intersect1d(cpm_dataset.columns, full_list)]  # find the mutual isoform between main datset and subdatset \n",
        "  \n",
        "  data.reset_index(inplace=True)\n",
        "  data.rename(columns={ data.columns[0]: \"sample_id\" }, inplace = True)\n",
        "\n",
        "  x = nofeats_ds['sample_id'].values.tolist()\n",
        "  data1= data.loc[data['sample_id'].isin(x)]\n",
        "  result = pd.merge(data1, nofeats_ds, on='sample_id')\n",
        "  result\n",
        "  result.rename(columns={'sample_label':'subtype'}, inplace=True )\n",
        " \n",
        "  # result.to_csv(name +\".csv\", index=False) # save as csv file \n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kASP_N3D_Z9q"
      },
      "source": [
        " DATASET 1 CON FS PAM50\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKDm9YMLAZJe"
      },
      "outputs": [],
      "source": [
        "# List of feature space name \n",
        "feature_space_files =[\"FEATURE_SPACE6(MAIN)\", \"FEATURE_SPACE1(PAM)\", \"FEATURE_SPACE2(PAM)\",\"FEATURE_SPACE1(LIMMA)\",\"FEATURE_SPACE2(LIMMA)\", \"FEATURE_SPACE7(pamsimilarity)\",\"FEATURE_SPACE8(limmasimilarity)\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOyi2GPFZvQn",
        "outputId": "9b3434e3-fad8-414a-b6ed-918af80d8f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (410, 131)\n",
            "X_test size: (127, 131)\n"
          ]
        }
      ],
      "source": [
        "# Training Data import:\n",
        "train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\", 'trainingset', training_ds, 'none') \n",
        "X_train_pam = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n",
        "Y_train_pam =train.subtype\n",
        "print(\"X_train size:\", X_train_pam.shape)\n",
        "\n",
        "# Testing Data import:\n",
        "test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\",'testingset', testing_ds,'none' ) \n",
        "X_test_pam = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n",
        "Y_test_pam = test.subtype\n",
        "print(\"X_test size:\", X_test_pam.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZIvQC6W_fHg"
      },
      "source": [
        "DATASET 2 CON FS LIMMA50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xuVX_FkAHjX",
        "outputId": "cbcc4d14-e976-4934-9fa4-2b2bd7058684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (410, 557)\n",
            "X_test size: (127, 557)\n"
          ]
        }
      ],
      "source": [
        "# Training Data import:\n",
        "train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\", 'trainingset', training_ds, 'none' ) \n",
        "X_train_limma = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n",
        "Y_train_limma =train.subtype\n",
        "print(\"X_train size:\", X_train_limma.shape)\n",
        "\n",
        "# Testing Data import:\n",
        "test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\",'testingset', testing_ds, 'none') \n",
        "X_test_limma = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n",
        "Y_test_limma = test.subtype\n",
        "print(\"X_test size:\", X_test_limma.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FpsrDco_i0T"
      },
      "source": [
        "DATASET 3 CON FS PAM50 E LOGE PREPROC\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SlmcbwTAINV",
        "outputId": "c47de679-b342-45c2-8f15-9a6a5602e0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (410, 131)\n",
            "X_test size: (127, 131)\n"
          ]
        }
      ],
      "source": [
        "# Training Data import:\n",
        "train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\", 'trainingset', training_ds, 'loge') \n",
        "X_train_pam_loge = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n",
        "Y_train_pam_loge=train.subtype\n",
        "print(\"X_train size:\", X_train_pam_loge.shape)\n",
        "\n",
        "# Testing Data import:\n",
        "test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\",'testingset', testing_ds,'loge' ) \n",
        "X_test_pam_loge = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n",
        "Y_test_pam_loge = test.subtype\n",
        "print(\"X_test size:\", X_test_pam_loge.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdSqftj5_oDp"
      },
      "source": [
        "DATASET 4 CON FS LIMMA50 E LOGE PREPROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo128XJEAI9_",
        "outputId": "059236ee-24e8-4217-d9cc-6ccb0972f402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (410, 557)\n",
            "X_test size: (127, 557)\n"
          ]
        }
      ],
      "source": [
        "# Training Data import:\n",
        "train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\", 'trainingset', training_ds, 'loge' ) \n",
        "X_train_limma_loge = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n",
        "Y_train_limma_loge =train.subtype\n",
        "print(\"X_train size:\", X_train_limma_loge.shape)\n",
        "\n",
        "# Testing Data import:\n",
        "test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\",'testingset', testing_ds, 'loge') \n",
        "X_test_limma_loge = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n",
        "Y_test_limma_loge = test.subtype\n",
        "print(\"X_test size:\", X_test_limma_loge.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NceijP63_1C_"
      },
      "source": [
        "DATASET 5 CON FS PAM50 E LOG2 PREPROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyWlNykdAJjZ",
        "outputId": "7221180d-30ea-40d6-ac08-54a3a3c60a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (410, 131)\n",
            "X_test size: (127, 131)\n"
          ]
        }
      ],
      "source": [
        "# Training Data import:\n",
        "train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\", 'trainingset', training_ds, 'log2') \n",
        "X_train_pam_log2 = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n",
        "Y_train_pam_log2 =train.subtype\n",
        "print(\"X_train size:\", X_train_pam_log2.shape)\n",
        "\n",
        "# Testing Data import:\n",
        "test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\",'testingset', testing_ds,'log2' ) \n",
        "X_test_pam_log2 = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n",
        "Y_test_pam_log2 = test.subtype\n",
        "print(\"X_test size:\", X_test_pam_log2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agW5bW6s_4ja"
      },
      "source": [
        "DATASET 6 CON FS LIMMA50 E LOG2 PREPROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbc56NqGAKIw",
        "outputId": "2850038f-692a-4e53-d1eb-a9e9ec892d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (410, 557)\n",
            "X_test size: (127, 557)\n"
          ]
        }
      ],
      "source": [
        "# Training Data import:\n",
        "train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\", 'trainingset', training_ds, 'log2' ) \n",
        "X_train_limma_log2 = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n",
        "Y_train_limma_log2 =train.subtype\n",
        "print(\"X_train size:\", X_train_limma_log2.shape)\n",
        "\n",
        "# Testing Data import:\n",
        "test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\",'testingset', testing_ds, 'log2') \n",
        "X_test_limma_log2 = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n",
        "Y_test_limma_log2 = test.subtype\n",
        "print(\"X_test size:\", X_test_limma_log2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0I2qr2H_8fP"
      },
      "source": [
        "DATASET 7 CON FS REDUCED FROM PAM50 E LOG PREPROCESSING (2 since more standard procedure and similar results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtKWfvmOD30B",
        "outputId": "b0b31afc-0b9e-4e8f-e1b9-42b6cadb631a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=LogisticRegression(C=1, penalty='l1',\n",
              "                                             solver='liblinear'))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
        "sel_.fit(X_train_pam_log2,Y_train_pam_log2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaUzjJbsD3sq"
      },
      "outputs": [],
      "source": [
        "sel_.get_support()\n",
        "selected_feat = X_train_pam_log2.columns[(sel_.get_support())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqYWFbAuD3jZ",
        "outputId": "78351c20-94a1-4c97-edb5-a52852606173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total features: 131\n",
            "selected features: 118\n",
            "Percentage features with coefficients shrank to zero: 15.801526717557252\n"
          ]
        }
      ],
      "source": [
        "print('total features: {}'.format((X_train_pam_log2.shape[1])))\n",
        "print('selected features: {}'.format(len(selected_feat)))\n",
        "print('Percentage features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)/131*5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdEkItmBEKGw"
      },
      "outputs": [],
      "source": [
        "X_train_pam_log2_sel = X_train_pam_log2[selected_feat].copy()\n",
        "Y_train_pam_log2_sel = Y_train_pam_log2\n",
        "\n",
        "X_test_pam_log2_sel = X_test_pam_log2[selected_feat].copy()\n",
        "Y_test_pam_log2_sel = Y_test_pam_log2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oz4_Xl5ADNx"
      },
      "source": [
        "DATASET 8 CON FS REDUCED FROM LIMMA50 E LOG PREPROCESSING (choosen is 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLGJpecyALR-",
        "outputId": "20b31a0b-668d-4f94-a13a-d13ff331383f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=LogisticRegression(C=1, penalty='l1',\n",
              "                                             solver='liblinear'))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
        "sel_.fit(X_train_limma_log2,Y_train_limma_log2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZhWQ01wImRJ"
      },
      "outputs": [],
      "source": [
        "sel_.get_support()\n",
        "selected_feat = X_train_limma.columns[(sel_.get_support())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DIilh9xImK5",
        "outputId": "5f299134-d6af-489d-bbce-334e6c5bd806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total features: 557\n",
            "selected features: 226\n",
            "Percentage features with coefficients shrank to zero: 21.974865350089768\n"
          ]
        }
      ],
      "source": [
        "print('total features: {}'.format((X_train_limma_log2.shape[1])))\n",
        "print('selected features: {}'.format(len(selected_feat)))\n",
        "print('Percentage features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)/557*5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhHP4WFuImEs"
      },
      "outputs": [],
      "source": [
        "X_train_limma_log2_sel = X_train_limma_log2[selected_feat].copy()\n",
        "Y_train_limma_log2_sel = Y_train_limma_log2\n",
        "\n",
        "X_test_limma_log2_sel = X_test_limma_log2[selected_feat].copy()\n",
        "Y_test_limma_log2_sel = Y_test_limma_log2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKRISqrDAJ_H"
      },
      "source": [
        "DATASET 9 CON FS NEW E LOG PREPROCESSING (choose best try 2 for now) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8riMKSFueaj"
      },
      "source": [
        "#### feature selection on all features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw_h3CWwmLwk",
        "outputId": "152d1af3-3e84-4ebd-bc1f-4c8539d98657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (410, 49740)\n",
            "X_test size: (127, 49740)\n"
          ]
        }
      ],
      "source": [
        "# Training Data import:\n",
        "train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE6(MAIN)\", 'trainingset', training_ds, 'log2') \n",
        "X_train_pre_lasso = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n",
        "samples_train = train.sample_id\n",
        "Y_train_pre_lasso=train.subtype\n",
        "print(\"X_train size:\", X_train_pre_lasso.shape)\n",
        "\n",
        "# Testing Data import:\n",
        "test = extract_and_reduce_by_columns(base_feature_space,\"FEATURE_SPACE6(MAIN)\", 'testingset', testing_ds,  'log2') \n",
        "X_test_pre_lasso = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n",
        "Y_test_pre_lasso = test.subtype\n",
        "print(\"X_test size:\", X_test_pre_lasso.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSxUQyYouqC2",
        "outputId": "4652fa64-3726-4ed0-e6dc-a7e60b99bd27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=LogisticRegression(C=1, penalty='l1',\n",
              "                                             solver='liblinear'))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
        "sel_.fit(X_train_pre_lasso,Y_train_pre_lasso)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2LGGfY_us2K"
      },
      "outputs": [],
      "source": [
        "sel_.get_support()\n",
        "selected_feat = X_train_pre_lasso.columns[(sel_.get_support())]\n",
        "print(sel_.estimator_.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPzaBOVOu1Bu",
        "outputId": "b8372fcd-0c40-4b38-e3be-f9e69f76dae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total features: 49740\n",
            "selected features: 1563\n",
            "coefficients shrank to zero: 246722\n",
            "0.9920466425412143\n"
          ]
        }
      ],
      "source": [
        "print('total features: {}'.format((X_train_pre_lasso.shape[1])))\n",
        "print('selected features: {}'.format(len(selected_feat)))\n",
        "print('coefficients shrank to zero: {}'.format(\n",
        "      np.sum(sel_.estimator_.coef_ == 0)))\n",
        "\n",
        "perc_feat_selected = np.sum(sel_.estimator_.coef_ == 0)/ (49740*5)\n",
        "print(perc_feat_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlS8buXoKp2K"
      },
      "outputs": [],
      "source": [
        "X_train_lasso = X_train_pre_lasso[selected_feat].copy()\n",
        "Y_train_lasso = Y_train_pre_lasso\n",
        "\n",
        "X_test_lasso = X_test_pre_lasso[selected_feat].copy()\n",
        "Y_test_lasso = Y_test_pre_lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature Selection done with MRMR method; the choice of number of features to keep is based on an average between the other feature selection methods"
      ],
      "metadata": {
        "id": "L7MVGIwewgga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choosing the selected by the lasso for speed reasons and since they include a big part of limma and pam 50 ones which are more restricting\n",
        "mrmr_features = mrmr_classif(X=X_train_lasso, y=Y_train_lasso, K=750)\n",
        "\n",
        "# Next steps: check how many of the chosen features overlap with selected with lasso, pam50 and limam50\n",
        "# in other training notebook: check how the models perform on it "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6aLvaFLyYpo",
        "outputId": "28e93c52-910d-4438-859b-f3a1ceefa0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [05:17<00:00,  2.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mrmr_features)"
      ],
      "metadata": {
        "id": "Kh75r5nOwu18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03acba96-0a76-473d-e1af-5d16cbd9193a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['uc010tpz.1', 'uc004ahm.2', 'uc003fdb.1', 'uc002hst.2', 'uc001wuf.2', 'uc003ojq.1', 'uc011eet.1', 'uc003mtp.2', 'uc002vwt.2', 'uc003sts.2', 'uc001slf.2', 'uc002amc.2', 'uc010jti.2', 'uc003qoo.3', 'uc003str.2', 'uc002hsl.2', 'uc010fyt.1', 'uc010fjf.2', 'uc003aed.2', 'uc011akl.1', 'uc003qol.2', 'uc002hsq.2', 'uc003qnt.2', 'uc002vwu.2', 'uc003yhc.2', 'uc001ygx.2', 'uc011eey.1', 'uc001cbj.2', 'uc002hsd.2', 'uc001cix.2', 'uc002bnh.3', 'uc002zav.2', 'uc001gtv.2', 'uc003ovb.2', 'uc011dev.1', 'uc002bsq.1', 'uc002hbq.2', 'uc002opb.3', 'uc001gxx.3', 'uc002ijx.3', 'uc010wek.1', 'uc002hxg.3', 'uc003hxc.1', 'uc002rbp.1', 'uc001mhh.1', 'uc011lwk.1', 'uc003qon.3', 'uc004ays.2', 'uc001qrg.2', 'uc002jmj.3', 'uc003pih.1', 'uc002hsi.1', 'uc004atb.2', 'uc003oon.2', 'uc002tlm.2', 'uc001sck.2', 'uc003flk.2', 'uc002huj.1', 'uc011mjf.1', 'uc002uid.1', 'uc010wei.1', 'uc003etn.2', 'uc003mau.2', 'uc003ybr.1', 'uc003gpp.2', 'uc003bhw.1', 'uc004bqi.2', 'uc003xnt.2', 'uc001mhi.1', 'uc010cwc.2', 'uc001hir.1', 'uc001omo.1', 'uc001qlf.2', 'uc010kio.2', 'uc002ltc.2', 'uc001kqf.2', 'uc002gkm.2', 'uc003gkd.3', 'uc002hsr.2', 'uc002jvf.2', 'uc003aun.1', 'uc002ijv.3', 'uc001atm.2', 'uc001lkf.2', 'uc010dmy.2', 'uc002htn.1', 'uc002veh.1', 'uc003ewe.2', 'uc001bdb.2', 'uc002ahf.3', 'uc001zki.2', 'uc001qmu.2', 'uc002hss.2', 'uc002zax.1', 'uc003sou.2', 'uc001kiq.3', 'uc003hyk.2', 'uc009xyr.2', 'uc003ldb.1', 'uc009vyd.1', 'uc002qyj.2', 'uc002ydm.2', 'uc003usw.1', 'uc002rbk.1', 'uc002hsj.2', 'uc003lqs.2', 'uc001xap.2', 'uc002vev.2', 'uc010ovg.1', 'uc001pmf.1', 'uc001gtw.3', 'uc002xws.2', 'uc002uel.2', 'uc001rux.2', 'uc001fdr.2', 'uc011bsq.1', 'uc001qfe.1', 'uc003yoz.2', 'uc003qok.1', 'uc002xlb.1', 'uc001xlt.1', 'uc001gcq.1', 'uc002pui.2', 'uc001lci.2', 'uc002liz.3', 'uc001cpl.2', 'uc002bul.2', 'uc003gou.2', 'uc002huq.2', 'uc001ibr.2', 'uc001pgg.2', 'uc010cwb.2', 'uc001sak.2', 'uc003eee.3', 'uc002opq.2', 'uc001ugm.3', 'uc002hus.2', 'uc003vpr.2', 'uc002hsp.2', 'uc001xls.1', 'uc010liz.2', 'uc002ysk.2', 'uc001zxb.1', 'uc003lcj.2', 'uc009zeb.2', 'uc003stg.2', 'uc001pwz.2', 'uc002wni.1', 'uc002jxc.2', 'uc002htk.1', 'uc001yri.3', 'uc009wsd.2', 'uc002xsl.2', 'uc009xgq.2', 'uc002xvo.2', 'uc001kic.2', 'uc002xtw.1', 'uc011ecf.1', 'uc002ozs.2', 'uc001nsg.2', 'uc003ncw.2', 'uc002lpo.2', 'uc001dlr.3', 'uc001fhl.3', 'uc010vli.1', 'uc011apl.1', 'uc010mll.2', 'uc010yvs.1', 'uc001bbv.1', 'uc001mpm.2', 'uc002kwj.3', 'uc010cwi.2', 'uc004cyg.2', 'uc002jvj.1', 'uc002eli.2', 'uc002jgz.1', 'uc003dxb.3', 'uc001pgh.2', 'uc002urs.2', 'uc010ukc.1', 'uc001ydd.1', 'uc009yih.1', 'uc002iju.3', 'uc001dmi.2', 'uc003yox.2', 'uc004awt.2', 'uc002lit.1', 'uc003hxb.1', 'uc003gos.2', 'uc003ewm.2', 'uc010bon.2', 'uc002vdf.1', 'uc001mvp.1', 'uc010scd.1', 'uc001bzi.2', 'uc001nyc.2', 'uc003suu.2', 'uc011kyf.1', 'uc010qbe.1', 'uc001ehz.2', 'uc010mon.1', 'uc002fkm.2', 'uc002kwl.3', 'uc002cky.2', 'uc003lue.3', 'uc002hso.2', 'uc004asw.2', 'uc002hfs.1', 'uc002ibj.2', 'uc003zxo.3', 'uc010ppj.1', 'uc002mbu.1', 'uc002ckz.2', 'uc001ijy.1', 'uc002kwi.3', 'uc003mco.1', 'uc003hqs.3', 'uc004cxj.2', 'uc002xze.1', 'uc002voh.3', 'uc003bcr.2', 'uc010nfa.2', 'uc002hrs.2', 'uc001dfq.2', 'uc004dwf.2', 'uc002efg.1', 'uc001cmg.3', 'uc001omg.1', 'uc010cwj.2', 'uc001phb.2', 'uc003jjl.3', 'uc002gvt.2', 'uc003dkl.2', 'uc011kco.1', 'uc003cjl.2', 'uc001sgk.2', 'uc009you.1', 'uc002tmx.2', 'uc010dbr.2', 'uc003cpb.3', 'uc001gtu.2', 'uc004bif.2', 'uc010ocm.1', 'uc003kjx.2', 'uc003oyv.2', 'uc001dyn.2', 'uc001lfg.3', 'uc002kqw.2', 'uc010hyc.2', 'uc001hiq.1', 'uc002xms.2', 'uc001nnl.2', 'uc010veg.1', 'uc001caz.2', 'uc010zpy.1', 'uc003yxf.1', 'uc002ira.3', 'uc002tie.2', 'uc001cqo.1', 'uc002hxh.2', 'uc003pjb.3', 'uc001san.2', 'uc003fqi.2', 'uc003mcn.1', 'uc001rvo.2', 'uc010ppk.1', 'uc004clp.2', 'uc003fdl.2', 'uc003sxq.2', 'uc002xvi.1', 'uc001ima.2', 'uc003mzp.3', 'uc003maq.1', 'uc002zmp.1', 'uc001cuv.2', 'uc003ysi.2', 'uc001bsn.2', 'uc001din.2', 'uc002iog.2', 'uc002bdp.2', 'uc003xsy.1', 'uc003zdj.2', 'uc003jfn.1', 'uc002tag.2', 'uc001ctt.2', 'uc002nxq.1', 'uc004ajf.1', 'uc002leu.2', 'uc002ttb.2', 'uc003qoi.2', 'uc003xos.2', 'uc001tvw.2', 'uc002cju.1', 'uc001kxr.2', 'uc001hic.2', 'uc003goq.3', 'uc003mfl.2', 'uc001fto.2', 'uc001fck.1', 'uc002csn.2', 'uc002jft.1', 'uc010qtj.1', 'uc001ydm.2', 'uc001gpd.1', 'uc001muu.3', 'uc002yld.1', 'uc003qpy.2', 'uc002mbq.3', 'uc003xcm.1', 'uc001eam.2', 'uc001sal.3', 'uc002taf.2', 'uc001nxn.2', 'uc003lmi.3', 'uc001baf.2', 'uc001jjy.1', 'uc002hxf.1', 'uc002xkg.2', 'uc002xzt.2', 'uc003frw.1', 'uc001sab.2', 'uc003nss.2', 'uc003evy.3', 'uc001nlo.3', 'uc011laz.1', 'uc002iuh.2', 'uc003eid.3', 'uc002zaq.2', 'uc002hvm.1', 'uc002iqq.2', 'uc002zzn.1', 'uc001zns.3', 'uc003wyr.2', 'uc003yvd.2', 'uc003vtq.2', 'uc003iii.2', 'uc003aqs.1', 'uc003wev.1', 'uc001fbs.2', 'uc001cai.1', 'uc002jkp.2', 'uc001gzi.2', 'uc003fox.2', 'uc003jmh.2', 'uc002hxb.1', 'uc002orl.2', 'uc003jfd.2', 'uc001xrn.2', 'uc002rks.2', 'uc003jeq.2', 'uc002ewf.2', 'uc003fsc.2', 'uc003ipp.3', 'uc011ltb.1', 'uc002cir.1', 'uc002orm.2', 'uc001eoo.1', 'uc002tqn.1', 'uc002zdr.2', 'uc002yfe.1', 'uc002ckx.2', 'uc003hld.2', 'uc001nbw.1', 'uc010sib.1', 'uc003xuw.2', 'uc004chv.3', 'uc003zld.2', 'uc002aex.2', 'uc003cnx.3', 'uc001gpa.1', 'uc002sjw.2', 'uc001gcn.2', 'uc001vmw.2', 'uc002vnl.3', 'uc010zho.1', 'uc003flh.3', 'uc002kws.2', 'uc003gvo.2', 'uc009xdc.2', 'uc002huk.1', 'uc003lzh.2', 'uc002bqm.2', 'uc003yan.2', 'uc002kdv.1', 'uc003xhm.2', 'uc003jfr.2', 'uc001def.1', 'uc002vew.2', 'uc003xwj.2', 'uc001gvo.2', 'uc003pdc.3', 'uc004asx.2', 'uc001iox.1', 'uc003exb.1', 'uc001dbh.2', 'uc003qbn.2', 'uc002hwz.2', 'uc003xzj.2', 'uc002ugz.3', 'uc003tqk.2', 'uc003zag.1', 'uc002bqo.2', 'uc001sxu.2', 'uc001cba.1', 'uc002fja.2', 'uc010yur.1', 'uc003ozs.2', 'uc002sgs.3', 'uc002jri.2', 'uc002jsv.2', 'uc001gsl.2', 'uc001ntc.2', 'uc001ozt.2', 'uc003epv.1', 'uc001ydp.2', 'uc010ovc.1', 'uc003mza.2', 'uc003kgh.2', 'uc003yue.1', 'uc002xmw.2', 'uc010eea.2', 'uc001vyx.2', 'uc003ncx.1', 'uc001ftp.3', 'uc002gjv.2', 'uc002ues.2', 'uc002gvr.2', 'uc002veg.1', 'uc003xwl.2', 'uc002hwy.2', 'uc002wtq.1', 'uc002lpx.1', 'uc002lgo.2', 'uc002eil.2', 'uc002ubr.1', 'uc001tjf.2', 'uc001fwb.1', 'uc002dgy.2', 'uc004aob.1', 'uc001lke.2', 'uc002ibd.1', 'uc010omo.1', 'uc003skv.3', 'uc003heh.2', 'uc001phi.2', 'uc001syv.2', 'uc002psd.2', 'uc003pag.2', 'uc002ddn.2', 'uc011eev.1', 'uc003ybu.1', 'uc002dgw.2', 'uc001crc.1', 'uc003xmb.3', 'uc003kjw.2', 'uc003oqn.2', 'uc002xxg.1', 'uc002pbx.3', 'uc001rcs.2', 'uc003yal.2', 'uc001iie.1', 'uc001zxw.2', 'uc001rtm.2', 'uc002zxx.2', 'uc001txj.1', 'uc003iqm.1', 'uc003uhy.1', 'uc001oud.2', 'uc011lhy.1', 'uc003oqp.3', 'uc001nsh.2', 'uc010var.1', 'uc003wzk.3', 'uc010zwq.1', 'uc002mwe.2', 'uc003xhh.3', 'uc002ynu.1', 'uc001pwf.2', 'uc001cgj.2', 'uc003wcf.1', 'uc002fou.1', 'uc003pwm.2', 'uc002ici.1', 'uc003xot.2', 'uc003ula.2', 'uc002tvl.2', 'uc010rdb.1', 'uc001taw.2', 'uc001doe.2', 'uc001pro.1', 'uc003kjq.2', 'uc003jjm.2', 'uc001nsj.2', 'uc010wmt.1', 'uc002vnv.2', 'uc001wpy.2', 'uc010xbi.1', 'uc002gju.2', 'uc002pca.3', 'uc004dzf.3', 'uc001kjt.2', 'uc010cwa.2', 'uc002qzx.2', 'uc010guu.1', 'uc003wyn.2', 'uc004cab.1', 'uc010grl.2', 'uc003lkn.1', 'uc001bax.2', 'uc011jyh.1', 'uc001qnx.2', 'uc001cik.2', 'uc001ewl.2', 'uc003tfo.3', 'uc003nhl.1', 'uc002zxy.2', 'uc003srq.2', 'uc002orx.2', 'uc001ntb.2', 'uc003fae.1', 'uc002ggj.3', 'uc001ido.2', 'uc002ohu.1', 'uc003uvu.1', 'uc010faq.2', 'uc011dpd.1', 'uc002wft.2', 'uc001nnd.3', 'uc003fee.2', 'uc010ekb.1', 'uc001ljt.2', 'uc011edl.1', 'uc001iic.2', 'uc002swe.2', 'uc001dgg.2', 'uc001wku.3', 'uc009vrj.2', 'uc002vsb.3', 'uc001fbw.1', 'uc004ddq.2', 'uc003hus.3', 'uc003qht.2', 'uc009ynx.2', 'uc003iow.2', 'uc010rlo.1', 'uc010qal.1', 'uc003lcp.1', 'uc001diw.2', 'uc002omp.3', 'uc003ycd.2', 'uc004fin.2', 'uc002dhm.1', 'uc010ekv.2', 'uc003htn.3', 'uc001cqt.2', 'uc001tfj.2', 'uc010ehg.1', 'uc001dmj.2', 'uc004aar.1', 'uc002wyw.1', 'uc002fph.1', 'uc001doz.2', 'uc003bbs.3', 'uc002pmw.2', 'uc003yah.2', 'uc003hcn.2', 'uc001eid.2', 'uc002nut.3', 'uc001nsk.2', 'uc003nvi.3', 'uc002yuf.1', 'uc002otu.2', 'uc001btk.1', 'uc011cqx.1', 'uc002lis.2', 'uc003srv.2', 'uc001fun.1', 'uc003lui.2', 'uc003fdj.2', 'uc009wgo.2', 'uc003xlz.2', 'uc001fhy.2', 'uc002xxe.1', 'uc010one.1', 'uc001znt.3', 'uc002mrp.2', 'uc003zdl.1', 'uc002usk.2', 'uc002hsc.2', 'uc003yhj.2', 'uc003qcz.2', 'uc011dqi.1', 'uc001bnj.3', 'uc003ltl.1', 'uc011bfo.1', 'uc003fre.1', 'uc003tnb.2', 'uc011eeq.1', 'uc001nnm.2', 'uc002jpi.3', 'uc001oyx.2', 'uc001nxh.2', 'uc010yjs.1', 'uc003qen.3', 'uc011aoa.1', 'uc001afq.2', 'uc002odc.2', 'uc011kaz.1', 'uc009yfi.2', 'uc001mcw.2', 'uc001saa.1', 'uc002wyj.2', 'uc003zjt.2', 'uc001ojc.1', 'uc003fur.2', 'uc010yqc.1', 'uc001qqz.1', 'uc010wpt.1', 'uc001txh.1', 'uc010mab.2', 'uc002htu.2', 'uc002jjn.2', 'uc003nyj.3', 'uc002kwu.3', 'uc002hsb.2', 'uc002zhg.2', 'uc003lay.2', 'uc002rfo.1', 'uc003amc.2', 'uc011dez.1', 'uc002zap.2', 'uc001vll.1', 'uc001qra.1', 'uc002lhc.2', 'uc010uux.1', 'uc001cqu.1', 'uc009yng.1', 'uc004ejl.2', 'uc009zmn.1', 'uc001ywy.1', 'uc011lyh.1', 'uc002luj.2', 'uc002zcu.2', 'uc010qek.1', 'uc003fra.2', 'uc010uuz.1', 'uc001ehb.2', 'uc001mnz.3', 'uc002pjn.2', 'uc001oxe.2', 'uc001hny.3', 'uc003bdt.1', 'uc003vqc.2', 'uc001kce.3', 'uc001mvw.2', 'uc001vqx.2', 'uc003sxs.3', 'uc001hxv.1', 'uc010xry.1', 'uc002jqw.2', 'uc003tzq.2', 'uc002ioa.2', 'uc003nrn.2', 'uc001fmr.2', 'uc001cdf.1', 'uc002wtp.2', 'uc003btq.2', 'uc001bny.1', 'uc002fxb.1', 'uc001dfw.2', 'uc010ipj.2', 'uc001uqm.1', 'uc003ewl.2', 'uc010mrp.2', 'uc002ckv.2', 'uc003zvo.2', 'uc001wjm.2', 'uc001orm.1', 'uc001bck.1', 'uc004bek.3', 'uc001hib.2', 'uc002rvx.2', 'uc003yxd.1', 'uc001ycv.2', 'uc001tcr.2', 'uc002kvk.2', 'uc010kze.2', 'uc002xga.2', 'uc003cht.2', 'uc001vhl.2', 'uc002hxv.2', 'uc011abj.1', 'uc003efi.2', 'uc003yzd.2', 'uc001rvz.2', 'uc001evc.2', 'uc002ixr.1', 'uc003fac.1', 'uc002dwc.2', 'uc001szl.1', 'uc011dve.1', 'uc010kdr.2', 'uc002hrz.2', 'uc002dql.2', 'uc001yds.2', 'uc002uqj.1', 'uc001wms.2', 'uc001nwd.2', 'uc003ujq.1', 'uc001fko.2', 'uc010lez.2', 'uc010xyt.1', 'uc003uxt.2', 'uc003gfi.3', 'uc001rcn.1', 'uc001qot.1', 'uc010yux.1', 'uc004dap.2', 'uc002hgt.2', 'uc011aci.1', 'uc003egh.1', 'uc004anf.3', 'uc001hms.2', 'uc003uhd.3', 'uc002nke.2', 'uc001zpd.2', 'uc001hsr.1', 'uc003bei.1', 'uc001nlt.3', 'uc003tqc.3', 'uc002zbc.2', 'uc004efw.3', 'uc003ngo.2', 'uc003hzr.3', 'uc001wvg.3', 'uc001ktb.2', 'uc001cze.2', 'uc010weo.1', 'uc003fdh.2', 'uc003yyq.1', 'uc002rct.2', 'uc003ixx.3', 'uc002xnu.2', 'uc001evp.1', 'uc003jpk.2', 'uc001iko.3', 'uc003fzw.3', 'uc001kbw.2', 'uc001bla.2', 'uc011dtb.1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mrmr = X_train_lasso[mrmr_features].copy()\n",
        "Y_train_mrmr = Y_train_lasso\n",
        "\n",
        "X_test_mrmr = X_test_lasso[mrmr_features].copy()\n",
        "Y_test_mrmr = Y_test_lasso"
      ],
      "metadata": {
        "id": "ih7dudIswuzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_mrmr.shape, X_test_mrmr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-XByxFjzz5s",
        "outputId": "3f7159be-402e-4023-823a-0bb2a43dc9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(410, 750) (127, 750)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step is to do tuning on this k method to find the optimal number of features"
      ],
      "metadata": {
        "id": "ys3HOcKqyc4a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS8speNhmNy4"
      },
      "source": [
        "### Model training, evaluation and saving of results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6pLIoMgkXOZ"
      },
      "outputs": [],
      "source": [
        "def write_results(results, final_path, name_file):\n",
        "      '''\n",
        "      Function to write results metrics and confing into a csv file with as name the current date\n",
        "      '''\n",
        "      \n",
        "      # datetime object containing current date and time\n",
        "      now = datetime.now()\n",
        "      dt_string = now.strftime(\"%d%m%Y%H%M%S\")\n",
        "      dt = now.strftime(\"%d%m%Y\")\n",
        "\n",
        "      if not os.path.exists(results_path+final_path+dt+'/'):\n",
        "        os.mkdir(results_path+final_path+dt+'/')\n",
        "\n",
        "      \n",
        "      df = pd.DataFrame(results)\n",
        "      df.to_csv(results_path+final_path+dt+'/'+name_file+dt_string+\".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM9h4lt8kf3L"
      },
      "outputs": [],
      "source": [
        "def training_and_saving_after_cv_and_single_split(which_ds, X_train, Y_train,X_test, Y_test, scores, param_values, model):\n",
        "\n",
        "  C = []\n",
        "  l1_ratio = []\n",
        "  cv_best = []\n",
        "  score_test_balanced_accuracy = []\n",
        "  score_test_accuracy = []\n",
        "  precision = []\n",
        "  recall = []\n",
        "  f1=[]\n",
        "\n",
        "  for index, score in enumerate(scores):\n",
        "      # -------RESULTS in CROSS_VALIDATION-----------\n",
        "      print(\"Tuning hyper-parameters for %s\" % score)\n",
        "      # Fit and hyperparameter search\n",
        "      selected_model = GridSearchCV(model(), param_values, scoring=score, cv=10)\n",
        "      selected_model.fit(X_train, Y_train)\n",
        "      # found best model and fit on training\n",
        "      print(\"Parameter setting that gave the best results on the hold out data: \",  selected_model.best_params_)\n",
        "      print(\"Mean cross-validated score of the best_estimator found, mean, std dev: \",  selected_model.best_score_, selected_model.cv_results_['mean_test_score'], selected_model.cv_results_['std_test_score'] )\n",
        "\n",
        "      # save top config and score from grid search (only accuracy or balanced accuracy)\n",
        "      # evaltype datasetdetails modelname parameters balancedaccuracy\n",
        "      dic_result = {}\n",
        "      dic_result['eval_type']= ['GRID SEARCH RESULTS']\n",
        "      dic_result['dataset_details']= [which_ds]\n",
        "      dic_result['model_name']=  [model.__name__ ]\n",
        "      dic_result['top_parameters']= [str(selected_model.best_params_)]\n",
        "      dic_result['name_score']= [score]\n",
        "      dic_result['best_score'] = [selected_model.best_score_]\n",
        "      dic_result['mean_test_score'] = [selected_model.best_score_]\n",
        "      index, = np.where(selected_model.cv_results_['mean_test_score']==selected_model.best_score_)\n",
        "      dic_result['std_test_score'] =selected_model.cv_results_['std_test_score'][index[0]]\n",
        "\n",
        "      df_result = pd.DataFrame.from_dict(dic_result)\n",
        "      print('Grid search results: ', df_result)\n",
        "      write_results(df_result,model.__name__ +'/', 'cv_on_'+score)\n",
        "\n",
        "      # use top config and trained model for evaluation on test\n",
        "      y_true, y_pred = Y_test, selected_model.predict(X_test)\n",
        "\n",
        "      # save results from test\n",
        "      # evaltype datasetdetails modelname parameters balacc accc prec rec f1\n",
        "      dic_result = {}\n",
        "      dic_result['eval_type']= ['TEST GRID SEARCH RESULTS']\n",
        "      dic_result['dataset_details']= [which_ds]\n",
        "      dic_result['model_name']=  [model.__name__ ]\n",
        "      dic_result['top_parameters']= [str(selected_model.best_params_)]\n",
        "      dic_result['balanced_accuracy'] = [round(balanced_accuracy_score(y_true, y_pred), 3)]\n",
        "      dic_result['accuracy'] = [round(accuracy_score(y_true, y_pred), 3)]\n",
        "      dic_result['precision'] = [round(precision_score(y_true, y_pred, average=\"macro\"), 3)]\n",
        "      dic_result['recall'] = [round(recall_score(y_true, y_pred, average=\"macro\"), 3)]\n",
        "      dic_result['f1_macro'] = [round(f1_score(y_true, y_pred, average=\"macro\"),3)]\n",
        "      dic_result['f1_micro'] = [round(f1_score(y_true, y_pred, average=\"micro\"),3)]\n",
        "\n",
        "      df_result = pd.DataFrame.from_dict(dic_result)\n",
        "      print('Grid search results on test eval: ', df_result)\n",
        "      # not saved anymore because the results are the same as creating new model and performing eval on test set\n",
        "      # it was initiially introduced for verification\n",
        "      # write_results(df_result,model.__name__ +'/', 'testcv_on_'+score) \n",
        "\n",
        "      # create new model with top convig and evaluate for verification\n",
        "      check_model = model(**selected_model.best_params_)\n",
        "      check_model.fit(X_train, Y_train)\n",
        "      \n",
        "      y_true, y_pred = Y_test, check_model.predict(X_test)\n",
        "\n",
        "      # save again the scores\n",
        "      dic_result = {}\n",
        "      dic_result['eval_type']= ['TEST GRID SEARCH RESULTS']\n",
        "      dic_result['dataset_details']= [which_ds]\n",
        "      dic_result['model_name']=  [model.__name__ ]\n",
        "      dic_result['top_parameters']= [str(selected_model.best_params_)]\n",
        "      dic_result['balanced_accuracy'] = [round(balanced_accuracy_score(y_true, y_pred), 3)]\n",
        "      dic_result['accuracy'] = [round(accuracy_score(y_true, y_pred), 3)]\n",
        "      dic_result['precision'] = [round(precision_score(y_true, y_pred, average=\"macro\"), 3)]\n",
        "      dic_result['recall'] = [round(recall_score(y_true, y_pred, average=\"macro\"), 3)]\n",
        "      dic_result['f1_macro'] = [round(f1_score(y_true, y_pred, average=\"macro\"),3)]\n",
        "      dic_result['f1_micro'] = [round(f1_score(y_true, y_pred, average=\"micro\"),3)]\n",
        "\n",
        "      df_result = pd.DataFrame.from_dict(dic_result)\n",
        "      print('Results on test eval: ', df_result)\n",
        "      write_results(df_result,model.__name__ +'/', 'test_on_'+score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT8xxZKCAi0l"
      },
      "source": [
        "### Running section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t73Zit9ZAmuO"
      },
      "outputs": [],
      "source": [
        "# for each dataset\n",
        "# for each model\n",
        "# create all parameters and other details to pass to the fun\n",
        "# run training and saving function "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TTKj6F5Qe5_"
      },
      "source": [
        "Parameters definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJC2B6SJ9u-G",
        "outputId": "d288b1c1-4384-45b0-8064-83c3460f55a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'multi_class': ['ovr'], 'penalty': ['elasticnet'], 'solver': ['saga'], 'max_iter': [2000], 'C': [0.1, 0.01], 'l1_ratio': [0.01, 0.001]}]\n",
            "[{'kernel': ['poly'], 'degree': [2, 3], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100], 'max_iter': [1000], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n"
          ]
        }
      ],
      "source": [
        "# Configuration of parameters and name\n",
        "\n",
        "#GridSearch attributes\n",
        "# Set the parameters by cross-validation\n",
        "#'l1_ratio':[0.5], 'solver': ['saga'], 'penalty':['elasticnet']\n",
        "logreg_tuned_parameters = [{\n",
        "    'multi_class':  ['ovr'],\n",
        "    'penalty':['elasticnet'],\n",
        "    'solver': ['saga'], \n",
        "    'max_iter':[2000], \n",
        "    'C':  [ 0.1, 0.01], #[10 ** i for i in range(-2,1)],\n",
        "    'l1_ratio': [ 0.01, 0.001] #[10 ** i for i in range(-2,1)] #'l1_ratio':[0.5]}]\n",
        "    }]\n",
        "\n",
        "svc_tuned_parameters = [{\n",
        "    'kernel':['poly'],  \n",
        "    'degree': [1, 2, 3], # 1 for linear, 2 for polynomial\n",
        "    'gamma': [10 ** i for i in range(-3,3)],\n",
        "    'max_iter':[1000], \n",
        "    'C': [10 ** i for i in range(-3,3)]}]\n",
        "\n",
        "scores = [ \"accuracy\", \"balanced_accuracy\"]\n",
        "\n",
        "print(logreg_tuned_parameters)\n",
        "print(svc_tuned_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZOJmt1FQtng"
      },
      "source": [
        "dataset 1 with fs pam50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uod6Beh-RwYC"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('pam_fs', X_train_pam, Y_train_pam, X_test_pam, Y_test_pam, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('pam_fs', X_train_pam, Y_train_pam, X_test_pam, Y_test_pam, scores, svc_tuned_parameters, SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxh1TZjRRAah"
      },
      "source": [
        "dataset 2 with fs limma50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2IJxv7TR9Cm"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('limma_fs', X_train_limma, Y_train_limma, X_test_limma, Y_test_limma, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('limma_fs', X_train_limma, Y_train_limma, X_test_limma, Y_test_limma, scores, svc_tuned_parameters, SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DGtf1JsREFE"
      },
      "source": [
        "dataset 3 with fs pam50 and loge preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i31qIc-SFz4"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('pam_fs_loge', X_train_pam_loge, Y_train_pam_loge, X_test_pam_loge, Y_test_pam_loge, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('pam_fs_loge', X_train_pam_loge, Y_train_pam_loge, X_test_pam_loge, Y_test_pam_loge, scores, svc_tuned_parameters, SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pRSP59wRKaz"
      },
      "source": [
        "dataset 4 with fs limma50 and loge preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMUwDPEMSOcU"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('limma_fs_loge', X_train_limma_loge, Y_train_limma_loge, X_test_limma_loge, Y_test_limma_loge, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('limma_fs_loge', X_train_limma_loge, Y_train_limma_loge, X_test_limma_loge, Y_test_limma_loge, scores, svc_tuned_parameters, SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W80lqJ29RNj6"
      },
      "source": [
        "dataset 5 with fs pam50 and log2 preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbu6NgA5SngU"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('pam_fs_log2', X_train_pam_log2, Y_train_pam_log2, X_test_pam_log2, Y_test_pam_log2, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('pam_fs_log2', X_train_pam_log2, Y_train_pam_log2, X_test_pam_log2, Y_test_pam_log2, scores, svc_tuned_parameters, SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJaN3i-vRPpf"
      },
      "source": [
        "dataset 6 with fs limma50 and log2 preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4CQks0HSaxv"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('limma_fs_log2', X_train_limma_log2, Y_train_limma_log2, X_test_limma_log2, Y_test_limma_log2, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('limma_fs_log2', X_train_limma_log2, Y_train_limma_log2, X_test_limma_log2, Y_test_limma_log2, scores, svc_tuned_parameters, SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f69mEPIFRYoI"
      },
      "source": [
        "DATASET 7 CON FS REDUCED FROM PAM50 E LOG PREPROCESSING (choose the best between 2 and e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOm1HG0DSs9x"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('pam_fs_log2_sel', X_train_pam_log2_sel, Y_train_pam_log2_sel, X_test_pam_log2_sel, Y_test_pam_log2_sel, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('pam_fs_log2_sel', X_train_pam_log2_sel, Y_train_pam_log2_sel, X_test_pam_log2_sel, Y_test_pam_log2_sel, scores, svc_tuned_parameters, SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxv981xjRc6M"
      },
      "source": [
        "DATASET 8 CON FS REDUCED FROM LIMMA50 E LOG PREPROCESSING (choose the best between 2 and e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KpvI_uoStrS"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('limma_fs_log2_sel', X_train_limma_log2_sel, Y_train_limma_log2_sel, X_test_limma_log2_sel, Y_test_limma_log2_sel, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('limma_fs_log2_sel', X_train_limma_log2_sel, Y_train_limma_log2_sel, X_test_limma_log2_sel, Y_test_limma_log2_sel, scores, svc_tuned_parameters, SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eghtWH-YRht3"
      },
      "source": [
        "DATASET 9 CON FS NEW with lasso for feature space E LOG PREPROCESSING (choose best try e for now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-vSuXT-9d0T"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('lasso_fs_loge_sel', X_train_lasso, Y_train_lasso, X_test_lasso, Y_test_lasso, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('lasso_fs_loge_sel', X_train_lasso, Y_train_lasso, X_test_lasso, Y_test_lasso, scores, svc_tuned_parameters, SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### DATASET 10 CON FS NEW with mrmr for feature space E LOG PREPROCESSING (choose best try e for now)"
      ],
      "metadata": {
        "id": "ijjYVKwTVJYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION with LOGISTIC REGRESSION\n",
        "training_and_saving_after_cv_and_single_split('mrmr_fs_log2_sel', X_train_mrmr, Y_train_mrmr, X_test_mrmr, Y_test_mrmr, scores, logreg_tuned_parameters, LogisticRegression)\n",
        "\n",
        "# EVALUATION with SVC\n",
        "training_and_saving_after_cv_and_single_split('mrmr_fs_log2_sel', X_train_mrmr, Y_train_mrmr, X_test_mrmr, Y_test_mrmr, scores, svc_tuned_parameters, SVC)"
      ],
      "metadata": {
        "id": "6KmqLpg900PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KixnzBjpWpdr"
      },
      "source": [
        "### Random Forest Classifier exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt73tc7fFOGx"
      },
      "outputs": [],
      "source": [
        "# EVALUATION with RandomForrest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_values= [{\n",
        "    'min_samples_split': [2,5,10],\n",
        "    'max_depth': [ 100],\n",
        "    'max_features': [ 'sqrt'],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'n_estimators': [200, 500, 750]\n",
        "    }]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 1\n",
        "training_and_saving_after_cv_and_single_split('pam_fs', X_train_pam, Y_train_pam, X_test_pam, Y_test_pam, scores,rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "gliPdxn7A_GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 2\n",
        "training_and_saving_after_cv_and_single_split('limma_fs', X_train_limma, Y_train_limma, X_test_limma, Y_test_limma, scores, rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "briy4bqcBBuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 3\n",
        "training_and_saving_after_cv_and_single_split('pam_fs_loge', X_train_pam_loge, Y_train_pam_loge, X_test_pam_loge, Y_test_pam_loge, scores, rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "cz7k_vMlBDOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 4\n",
        "training_and_saving_after_cv_and_single_split('limma_fs_loge', X_train_limma_loge, Y_train_limma_loge, X_test_limma_loge, Y_test_limma_loge, scores, rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "AFfiBmiOBFKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 5\n",
        "training_and_saving_after_cv_and_single_split('pam_fs_log2', X_train_pam_log2, Y_train_pam_log2, X_test_pam_log2, Y_test_pam_log2, scores, rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "gndFCDcsBGmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 6\n",
        "training_and_saving_after_cv_and_single_split('limma_fs_log2', X_train_limma_log2, Y_train_limma_log2, X_test_limma_log2, Y_test_limma_log2, scores, rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "RG4LRcCZBH6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 7\n",
        "training_and_saving_after_cv_and_single_split('pam_fs_log2_sel', X_train_pam_log2_sel, Y_train_pam_log2_sel, X_test_pam_log2_sel, Y_test_pam_log2_sel, scores, rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "ERAEsq4WBJux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 8\n",
        "training_and_saving_after_cv_and_single_split('limma_fs_log2_sel', X_train_limma_log2_sel, Y_train_limma_log2_sel, X_test_limma_log2_sel, Y_test_limma_log2_sel, scores, rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "dWl7YIoTBLkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 9\n",
        "training_and_saving_after_cv_and_single_split('lasso_fs_log2_sel', X_train_lasso, Y_train_lasso, X_test_lasso, Y_test_lasso, scores, rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "zl9xC6kCBOsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 10\n",
        "training_and_saving_after_cv_and_single_split('mrmr_fs_log2_sel', X_train_mrmr, Y_train_mrmr, X_test_mrmr, Y_test_mrmr, scores, rf_values,model=RandomForestClassifier)"
      ],
      "metadata": {
        "id": "D306aIByeAPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}