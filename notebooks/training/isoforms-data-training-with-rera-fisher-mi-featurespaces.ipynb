{"cells":[{"cell_type":"markdown","source":["# In this notebook, we show the steps taken to preprocess the **isoforms** expression data, generate and select features through feature selection strategies which include lasso, mrmr, fisher score thresholds, mutual information score thresholds and the new proposed method **ReRa**. After this, different models are tuned and evaluated in the classification task using training and test dataset.\n","\n"],"metadata":{"id":"h-qtlajy5enT"}},{"cell_type":"markdown","metadata":{"id":"1SWnwppH_28G"},"source":["Related links:\n","\n","*correlation pearson:*\n","https://towardsdatascience.com/what-it-takes-to-be-correlated-ce41ad0d8d7f\n","\n","https://towardsdatascience.com/pearson-coefficient-of-correlation-explained-369991d93404\n","\n","https://medium.com/@joseph.magiya/pearson-coefficient-of-correlation-using-pandas-ca68ce678c04\n","\n","\n","*fisher score:*\n","https://jundongl.github.io/scikit-feature/tutorial.html\n","\n","https://ranasinghiitkgp.medium.com/implementing-feature-selection-methods-for-machine-learning-bfa2e4b4e02\n","\n","*mutual information:*\n","https://towardsdatascience.com/select-features-for-machine-learning-model-with-mutual-information-534fe387d5c8"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28439,"status":"ok","timestamp":1675178417848,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"Hw0MVKdRVoTq","outputId":"704cdf3b-bcc9-4e7f-ea35-748321bc8f55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/Drive\n"]}],"source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/Drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdt0AYcVbPfN"},"outputs":[],"source":["# uncomment if needed: libraries to install on google colab\n","! pip install mrmr_selection\n","! pip install scikit-learn==0.24.2 # Downgrading the scikit learn library to obtain same results of previous experiments and Convergence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mFaV9WnyVwo1"},"outputs":[],"source":["# Imports\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV\n","from sklearn.metrics import precision_score, recall_score, accuracy_score, balanced_accuracy_score, f1_score, matthews_corrcoef, classification_report, make_scorer\n","from sklearn.linear_model import LogisticRegression, Lasso\n","from sklearn.ensemble import RandomForestClassifier\n","import matplotlib.pyplot as plt\n","from xlwt import Workbook\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","import os\n","from pandas_profiling import ProfileReport\n","from sklearn import svm\n","from sklearn.svm import LinearSVC, SVC\n","from datetime import datetime\n","from sklearn.feature_selection import SelectFromModel\n","import seaborn as sb\n","from collections import OrderedDict\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1144,"status":"ok","timestamp":1675178433487,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"hUQex00RgYSB","outputId":"402fb40e-0396-473e-b4c8-60f215b4a615"},"outputs":[{"output_type":"stream","name":"stdout","text":["scikit-image==0.18.3\n","scikit-learn==0.24.2\n"]}],"source":["! pip freeze | grep scikit # check scikit-learn version for conversion in grid search"]},{"cell_type":"markdown","metadata":{"id":"ay3Xy-3nxZHx"},"source":["### Download of all datasets with different preprocessing strategies and feature spaces"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLS8a3QiV22W"},"outputs":[],"source":["# Current working directory and other paths\n","cwd = os.getcwd()\n","print(cwd)\n","!cd Drive/\n","path = cwd + \"/Drive/My Drive/magistrale/BioinformaticsProject/data/\" ### <- insert here path to retrieve data\n","results_path = cwd + \"/Drive/My Drive/magistrale/BioinformaticsProject/results/\" ### <- insert here path to save results\n","\n","# Count per Million matrix\n","cpm_dataset = pd.read_csv(path+\"CPM.csv\",index_col=0) #read the main CPM dataset(67k × 719)\n","cpm_dataset = cpm_dataset.transpose() # (719 × 67k)\n","\n","# Training and Testing datasets\n","training_ds =  pd.read_excel( path+\"train_test_new.xlsx\", sheet_name=\"train_new\") # path+\"train_test_new.xlsx\", sheet_name=\"train_new\")\n","testing_ds = pd.read_excel( path+\"train_test_new.xlsx\", sheet_name=\"test_new\" ) # path+\"train_test_new.xlsx\", sheet_name=\"test_new\")\n","\n","# Feature space datesets\n","base_feature_space =path+\"FEATURE_SPACES(RAW +CPM).xlsx\"\n","# List of feature space name \n","feature_space_files =[\"FEATURE_SPACE6(MAIN)\", \"FEATURE_SPACE1(PAM)\", \"FEATURE_SPACE2(PAM)\",\"FEATURE_SPACE1(LIMMA)\",\"FEATURE_SPACE2(LIMMA)\", \"FEATURE_SPACE7(pamsimilarity)\",\"FEATURE_SPACE8(limmasimilarity)\"]"]},{"cell_type":"markdown","metadata":{"id":"li-MkXN9SrZO"},"source":["### Data estraction and preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKVKnq_mWLQm"},"outputs":[],"source":["def extract_and_reduce_by_columns(path, sheet_name, name, nofeats_ds, preproc_strategy: str= \"none\"): \n","  \"\"\"\n","     Function to extract dataset and a specific group of its columns.\n","\n","     path: the path where to get the data values (isoforms)\n","     sheet_name: the excel sheet were to get the columns to select for the data (isoforms)\n","     nofeats_ds: the dataset without the additional columns\n","     name: 'trainingset' or 'testingset' for the excel \n","     preproc_strategy: which preprocessing strategy to apply to the ds\n","\n","  \"\"\"\n","  full_df = pd.read_excel(path, sheet_name=sheet_name) # path of subdatset \n","  full_list= full_df['isoform'].values.tolist()  #exatrct the list of isoforms names as list\n","  if preproc_strategy == 'loge':\n","    log_cpm_dataset = np.log1p(cpm_dataset)\n","    data = log_cpm_dataset[np.intersect1d(log_cpm_dataset.columns, full_list)]\n","  elif preproc_strategy == 'log2':\n","    log_cpm_dataset = np.log2(cpm_dataset + 1) # constant added to avoid reaching zero\n","    data = log_cpm_dataset[np.intersect1d(log_cpm_dataset.columns, full_list)]\n","  elif preproc_strategy == 'normperrow':\n","    # normalize per rows\n","    data = cpm_dataset[np.intersect1d(cpm_dataset.columns, full_list)]\n","    data = data.div(data.sum(axis=1), axis=0) # ----> preprocessing scaling step to try, not working\n","  elif preproc_strategy == 'none':\n","    data = cpm_dataset[np.intersect1d(cpm_dataset.columns, full_list)]  # find the mutual isoform between main datset and subdatset \n","  \n","  data.reset_index(inplace=True)\n","  data.rename(columns={ data.columns[0]: \"sample_id\" }, inplace = True)\n","\n","  x = nofeats_ds['sample_id'].values.tolist()\n","  data1= data.loc[data['sample_id'].isin(x)]\n","  result = pd.merge(data1, nofeats_ds, on='sample_id')\n","  result\n","  result.rename(columns={'sample_label':'subtype'}, inplace=True )\n"," \n","  # result.to_csv(name +\".csv\", index=False) # save as csv file \n","  return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZH0TSixcWM5"},"outputs":[],"source":["# This functions shows the evaluation results for the entire test set and also the metrics for each single class\n","\n","def show_single_class_evaluation(y_pred: int, y_test: int, labels):\n","  print(\"Balanced accuracy: \", round(balanced_accuracy_score(y_test, y_pred), 3)) # not possible for single class\n","  print(\"Accuracy: \", round(accuracy_score(y_test, y_pred), 3)) # not possible for single class\n","  print('precision ', round(precision_score(y_test, y_pred, average=\"macro\"), 3))\n","  print('recall ', round(recall_score(y_test, y_pred, average=\"macro\"), 3))\n","  print('f1_macro ', round(f1_score(y_test, y_pred, average=\"macro\"),3))\n","  print('f1_micro ', round(f1_score(y_test, y_pred, average=\"micro\"),3))\n","  print(\"Precision: \", [round(i, 3) for i in precision_score(y_test, y_pred, average=None) ])\n","  print(\"Recall: \",  [round(i, 3) for i in recall_score(y_test, y_pred, average=None) ]) \n","  print(\"F1 Score: \", [round(i, 3) for i in f1_score(y_test, y_pred, average=None) ]) \n","  print('--------------------------------------------')\n","\n","  dic_result = {}\n","  dic_result['balanced_accuracy'] = [round(balanced_accuracy_score(y_test, y_pred), 3)]\n","  dic_result['accuracy'] = [round(accuracy_score(y_test, y_pred), 3)]\n","  for i in range(len(labels)):\n","    dic_result[labels[i]+'-precision'] =  round( precision_score(y_test, y_pred, average=None)[i], 3)\n","  for i in range(len(labels)):\n","    dic_result[labels[i]+'-recall'] =  round( recall_score(y_test, y_pred, average=None)[i], 3)\n","  for i in range(len(labels)):   \n","    dic_result[labels[i]+'-f1_score'] =  round( f1_score(y_test, y_pred, average=None)[i], 3)\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CKDm9YMLAZJe"},"outputs":[],"source":["# List of feature space names \n","feature_space_files =[\"FEATURE_SPACE6(MAIN)\", \"FEATURE_SPACE1(PAM)\", \"FEATURE_SPACE2(PAM)\",\"FEATURE_SPACE1(LIMMA)\",\"FEATURE_SPACE2(LIMMA)\", \"FEATURE_SPACE7(pamsimilarity)\",\"FEATURE_SPACE8(limmasimilarity)\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19680,"status":"ok","timestamp":1675178481291,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"S2cAJEFhN9Mb","outputId":"84855c3c-7280-423c-e211-c5132164d6b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train size: (410, 49740)\n","X_test size: (127, 49740)\n"]}],"source":["# Here the train and test set are created with the initial filterings to reach 49k features is \n","# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE6(MAIN)\", 'trainingset', training_ds, 'log2') \n","X_train_49kfs = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","samples_train = train.sample_id\n","Y_train_49kfs=train.subtype\n","print(\"X_train size:\", X_train_49kfs.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space,\"FEATURE_SPACE6(MAIN)\", 'testingset', testing_ds,  'log2') \n","X_test_49kfs = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_49kfs = test.subtype\n","print(\"X_test size:\", X_test_49kfs.shape)"]},{"cell_type":"markdown","metadata":{"id":"NceijP63_1C_"},"source":["DATASET with PAM50 Feature Space and LOG2 PREPROCESSING"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14603,"status":"ok","timestamp":1673808821849,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"JyWlNykdAJjZ","outputId":"f46f7235-1f8a-44f4-c76b-9ed266c2c3f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train size: (410, 131)\n","X_test size: (127, 131)\n"]}],"source":["# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\", 'trainingset', training_ds, 'log2') \n","X_train_pam_log2 = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","Y_train_pam_log2 =train.subtype\n","print(\"X_train size:\", X_train_pam_log2.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE7(pamsimilarity)\",'testingset', testing_ds,'log2' ) \n","X_test_pam_log2 = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_pam_log2 = test.subtype\n","print(\"X_test size:\", X_test_pam_log2.shape)"]},{"cell_type":"markdown","metadata":{"id":"agW5bW6s_4ja"},"source":["DATASET with LIMMA50 Feature Space and LOG2 PREPROCESSING"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11472,"status":"ok","timestamp":1673808833315,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"nbc56NqGAKIw","outputId":"4ab688a1-cdc2-4cb8-cad4-b1c40b69f6f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train size: (410, 557)\n","X_test size: (127, 557)\n"]}],"source":["# Training Data import:\n","train = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\", 'trainingset', training_ds, 'log2' ) \n","X_train_limma_log2 = train.drop([\"sample_id\",\"subtype\"],  axis = 1)\n","Y_train_limma_log2 =train.subtype\n","print(\"X_train size:\", X_train_limma_log2.shape)\n","\n","# Testing Data import:\n","test = extract_and_reduce_by_columns(base_feature_space, \"FEATURE_SPACE8(limmasimilarity)\",'testingset', testing_ds, 'log2') \n","X_test_limma_log2 = test.drop([\"sample_id\",\"subtype\"], axis = 1)\n","Y_test_limma_log2 = test.subtype\n","print(\"X_test size:\", X_test_limma_log2.shape)"]},{"cell_type":"markdown","metadata":{"id":"l0I2qr2H_8fP"},"source":["DATASET with features selected throgh LASSO REGRESSION from PAM50 and LOG2 PREPROCESSING "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1673808833661,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"jtKWfvmOD30B","outputId":"c3fd89cb-f02c-4823-f6d1-d55056512e1c"},"outputs":[{"data":{"text/plain":["SelectFromModel(estimator=LogisticRegression(C=1, penalty='l1',\n","                                             solver='liblinear'))"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n","sel_.fit(X_train_pam_log2,Y_train_pam_log2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaUzjJbsD3sq"},"outputs":[],"source":["sel_.get_support()\n","selected_feat = X_train_pam_log2.columns[(sel_.get_support())]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673808833662,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"HqYWFbAuD3jZ","outputId":"d501d948-9b11-4881-e833-2f907ff39d44"},"outputs":[{"name":"stdout","output_type":"stream","text":["total features: 131\n","selected features: 118\n","Percentage features with coefficients shrank to zero: 15.763358778625953\n"]}],"source":["print('total features: {}'.format((X_train_pam_log2.shape[1])))\n","print('selected features: {}'.format(len(selected_feat)))\n","print('Percentage features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)/131*5))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TdEkItmBEKGw"},"outputs":[],"source":["# Datasets wuth the reduced feature spaces\n","X_train_pam_log2_sel = X_train_pam_log2[selected_feat].copy()\n","Y_train_pam_log2_sel = Y_train_pam_log2\n","\n","X_test_pam_log2_sel = X_test_pam_log2[selected_feat].copy()\n","Y_test_pam_log2_sel = Y_test_pam_log2"]},{"cell_type":"markdown","metadata":{"id":"5oz4_Xl5ADNx"},"source":["DATASET with features selected throgh LASSO REGRESSION from LIMMA50 and LOG2 PREPROCESSING "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":573,"status":"ok","timestamp":1673808834230,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"PLGJpecyALR-","outputId":"3ee5c243-9cb4-4e4d-83a1-f53845b6db75"},"outputs":[{"data":{"text/plain":["SelectFromModel(estimator=LogisticRegression(C=1, penalty='l1',\n","                                             solver='liblinear'))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n","sel_.fit(X_train_limma_log2,Y_train_limma_log2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZhWQ01wImRJ"},"outputs":[],"source":["sel_.get_support()\n","selected_feat = X_train_limma_log2.columns[(sel_.get_support())]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1673808834230,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"-DIilh9xImK5","outputId":"c3c4176d-1c7c-4c76-ed54-0d16b4e96848"},"outputs":[{"name":"stdout","output_type":"stream","text":["total features: 557\n","selected features: 225\n","Percentage features with coefficients shrank to zero: 21.974865350089768\n"]}],"source":["print('total features: {}'.format((X_train_limma_log2.shape[1])))\n","print('selected features: {}'.format(len(selected_feat)))\n","print('Percentage features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)/557*5))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhHP4WFuImEs"},"outputs":[],"source":["# Datasets with feature space reduced\n","X_train_limma_log2_sel = X_train_limma_log2[selected_feat].copy()\n","Y_train_limma_log2_sel = Y_train_limma_log2\n","\n","X_test_limma_log2_sel = X_test_limma_log2[selected_feat].copy()\n","Y_test_limma_log2_sel = Y_test_limma_log2"]},{"cell_type":"markdown","metadata":{"id":"YbhSg1xcOBup"},"source":["## For the paper methodological anlysis, furhter feature spaces will be included which are: \n","1. selection of features through fisher score\n","2. selection of features through mutual information\n","3. selection of features through ReRa, having as initial feature speces pam50 ,limma50, fisher score and mutual information with diferent thresholds\n"]},{"cell_type":"markdown","metadata":{"id":"abbE3EEYOrfL"},"source":["### Feature space with Fisher Score ( and log2 preprocessing)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7173,"status":"ok","timestamp":1673856441538,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"fZIT8rxtWO9Q","outputId":"5ac817b5-f047-4207-e3dd-01216c82fbb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'scikit-feature'...\n","remote: Enumerating objects: 1089, done.\u001b[K\n","remote: Counting objects: 100% (132/132), done.\u001b[K\n","remote: Compressing objects: 100% (74/74), done.\u001b[K\n","remote: Total 1089 (delta 57), reused 132 (delta 57), pack-reused 957\u001b[K\n","Receiving objects: 100% (1089/1089), 194.81 MiB | 36.45 MiB/s, done.\n","Resolving deltas: 100% (643/643), done.\n"]}],"source":["# in order to compute the fisher score we need to clone and use this github project with uses sklearn to compute it\n","! git clone https://github.com/jundongl/scikit-feature.git\n","%cd scikit-feature/\n","! python setup.py install"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GTsM-FxPe2T"},"outputs":[],"source":["import skfeature\n","import skfeature.function.similarity_based.fisher_score as fisher_score\n","# computing all fisher scores for all 49k features\n","score = fisher_score.fisher_score(X_train_49kfs.values, Y_train_49kfs.values)\n","score.sort()\n","score_dataframe = pd.DataFrame(score)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1673808864187,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"8Two0-Ew8OPb","outputId":"e01facb7-6dc7-43ad-d682-5dd9df5dc3df"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-a884d9e4-e65f-4896-b247-e4e9f2b757dd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>49740.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.094051</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.132675</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000198</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.052348</td>\n","    </tr>\n","    <tr>\n","      <th>70%</th>\n","      <td>0.093724</td>\n","    </tr>\n","    <tr>\n","      <th>80%</th>\n","      <td>0.133039</td>\n","    </tr>\n","    <tr>\n","      <th>85%</th>\n","      <td>0.165264</td>\n","    </tr>\n","    <tr>\n","      <th>90%</th>\n","      <td>0.216286</td>\n","    </tr>\n","    <tr>\n","      <th>95%</th>\n","      <td>0.320291</td>\n","    </tr>\n","    <tr>\n","      <th>97%</th>\n","      <td>0.401856</td>\n","    </tr>\n","    <tr>\n","      <th>98%</th>\n","      <td>0.478569</td>\n","    </tr>\n","    <tr>\n","      <th>99%</th>\n","      <td>0.632633</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.979966</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a884d9e4-e65f-4896-b247-e4e9f2b757dd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a884d9e4-e65f-4896-b247-e4e9f2b757dd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a884d9e4-e65f-4896-b247-e4e9f2b757dd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                  0\n","count  49740.000000\n","mean       0.094051\n","std        0.132675\n","min        0.000198\n","50%        0.052348\n","70%        0.093724\n","80%        0.133039\n","85%        0.165264\n","90%        0.216286\n","95%        0.320291\n","97%        0.401856\n","98%        0.478569\n","99%        0.632633\n","max        3.979966"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["score_dataframe.describe([0.7, 0.8, 0.85, 0.9, 0.95, 0.97, 0.98, 0.99])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1673808916302,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"QGHwEBInRdpa","outputId":"e68da4d9-7b05-4803-a4fe-7fc83d78f7b1"},"outputs":[{"data":{"text/plain":["0.4018561997292888"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# The code for the actual generation and selection is commented \n","# # Creating the new dataframe with only the chosen features by this method -> THRESHOLD CHOSEN IS THE 95% percentile value\n","# fisher_score_selected_index = np.where(score >score_97[score_97.index == '97%'].values[0][0])[0]\n","# selected_col_names = X_train_49kfs.columns[fisher_score_selected_index ]\n","\n","# Load the previously saved and generated feature space with the current method\n","selected_col_names= pd.read_csv(path+\"/isoformsfs/mrmr_from12k.csv\", index_col=0,skiprows=1, names=['isoform_id'])\n","selected_col_names= selected_col_names['isoform_id'].tolist()\n","len(selected_col_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":240,"status":"ok","timestamp":1674586411863,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"M_q2kfLwcgCP","outputId":"659cb5eb-360a-4506-dcd3-1c24b4f60242"},"outputs":[{"name":"stdout","output_type":"stream","text":["(410, 750)\n","(127, 750)\n"]}],"source":["X_train_fisher = X_train_49kfs[selected_col_names]\n","print(X_train_fisher.shape)\n","\n","X_test_fisher = X_test_49kfs[selected_col_names]\n","print(X_test_fisher.shape)\n","\n","# Y of the datasets remain the same\n","Y_train_fisher = Y_train_49kfs\n","Y_test_fisher = Y_test_49kfs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQgOTZkd-nq6"},"outputs":[],"source":["# Uncomment to save the current feature space\n","# pd.DataFrame(selected_col_names).to_csv(path+\"/isoformsfs/fisher_th97.csv\")"]},{"cell_type":"markdown","metadata":{"id":"aFzU2EXe-gdn"},"source":["### Feature spaces from scores with mutual information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lh28KM2dq3oW"},"outputs":[],"source":["from sklearn.feature_selection import mutual_info_classif as MIC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UlS8buXoKp2K"},"outputs":[],"source":["# Computing mutual information scores for all 49k features using the library\n","mi_score = MIC(X_train_49kfs,Y_train_49kfs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1673856801545,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"lllmr4cJA4ZQ","outputId":"b10ffa18-0d6b-47b0-e99c-1fc6927c27a7"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-ddb9b334-f59d-4573-bb5b-178b2401fb1d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>49740.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.050626</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.055270</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.036075</td>\n","    </tr>\n","    <tr>\n","      <th>70%</th>\n","      <td>0.063142</td>\n","    </tr>\n","    <tr>\n","      <th>80%</th>\n","      <td>0.083432</td>\n","    </tr>\n","    <tr>\n","      <th>85%</th>\n","      <td>0.098878</td>\n","    </tr>\n","    <tr>\n","      <th>90%</th>\n","      <td>0.121053</td>\n","    </tr>\n","    <tr>\n","      <th>95%</th>\n","      <td>0.160291</td>\n","    </tr>\n","    <tr>\n","      <th>97%</th>\n","      <td>0.188779</td>\n","    </tr>\n","    <tr>\n","      <th>98%</th>\n","      <td>0.211624</td>\n","    </tr>\n","    <tr>\n","      <th>99%</th>\n","      <td>0.252749</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.524941</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddb9b334-f59d-4573-bb5b-178b2401fb1d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ddb9b334-f59d-4573-bb5b-178b2401fb1d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ddb9b334-f59d-4573-bb5b-178b2401fb1d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                  0\n","count  49740.000000\n","mean       0.050626\n","std        0.055270\n","min        0.000000\n","50%        0.036075\n","70%        0.063142\n","80%        0.083432\n","85%        0.098878\n","90%        0.121053\n","95%        0.160291\n","97%        0.188779\n","98%        0.211624\n","99%        0.252749\n","max        0.524941"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["mi_score_dataframe= pd.DataFrame(mi_score)\n","# with the describe we can se the distribution of the scores\n","mi_score_dataframe.describe([0.7, 0.8, 0.85, 0.9, 0.95, 0.97, 0.98, 0.99])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1673856801546,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"wHnPZkrdNoFj","outputId":"3662703a-1a8d-48e1-f483-cce7c5ce625b"},"outputs":[{"data":{"text/plain":["0.1887791224592662"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["score_97 = mi_score_dataframe.describe([ 0.97])\n","score_97[score_97.index == '97%'].values[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I05CyrnBv3xc"},"outputs":[],"source":["# The code for the actual generation and selection is commented \n","# # Creating the new dataframe with only the chosen features by this method -> THRESHOLD IS TH 95% percentile\n","# mi_score_selected_index = np.where(mi_score >score_97[score_97.index == '97%'].values[0][0])[0]\n","# selected_col_names = X_train_49kfs.columns[mi_score_selected_index ]\n","\n","\n","# Load the previously saved and generated feature space with the current method\n","selected_col_names= pd.read_csv(path+\"mutualinformation_th97.csv\", index_col=0,skiprows=1, names=['isoform_id'])\n","selected_col_names= selected_col_names['isoform_id'].tolist()\n","len(selected_col_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1673856801547,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"z60_9NYx7v_H","outputId":"4974e36a-681d-49c5-cf49-1759af2715fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["(410, 1493)\n","(127, 1493)\n"]}],"source":["X_train_mi = X_train_49kfs[selected_col_names]\n","print(X_train_mi.shape)\n","\n","X_test_mi = X_test_49kfs[selected_col_names]\n","print(X_test_mi.shape)\n","\n","Y_train_mi = Y_train_49kfs\n","Y_test_mi = Y_test_49kfs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MuH1wyXR-_D6"},"outputs":[],"source":["# Uncomment to save the current feature space\n","# pd.DataFrame(selected_col_names).to_csv(path+\"/isoformsfs/mutualinformation_th97.csv\")"]},{"cell_type":"markdown","metadata":{"id":"kdCL9PfPj4Tv"},"source":["### 10 Random feature spaces"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2643,"status":"ok","timestamp":1675178483931,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"7t7y2Xskj3Fu","outputId":"0e212d81-5eac-417b-b716-eba1b4163d1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n","Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n","Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n","Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n","Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n","Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n","Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n","Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n","Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n","Shape of the new train dataset (410, 887)\n","Shape of the new test dataset (127, 887)\n"]}],"source":["X_train_randoms = []\n","random_spaces_names = []\n","X_test_randoms = []\n","\n","for i in range(10):\n","  rand_selected_feat = pd.read_csv(path+\"isoformsfs/random_\"+str(i)+\".csv\", index_col=0,skiprows=1, names=['isoform_id'])\n","  rand_selected_feat = rand_selected_feat['isoform_id'].tolist()\n","\n","  selected_col_names =rand_selected_feat\n","  X_train_random = X_train_49kfs[selected_col_names]\n","  print(\"Shape of the new train dataset\", X_train_random.shape)\n","  X_test_random = X_test_49kfs[selected_col_names]\n","  print(\"Shape of the new test dataset\",X_test_random.shape)\n","\n","  X_train_randoms.append(X_train_random)\n","  X_test_randoms.append(X_test_random)\n","  random_spaces_names.append(\"random\"+str(i))"]},{"cell_type":"code","source":["Y_train_random = Y_train_49kfs\n","Y_test_random = T_test_49kfs"],"metadata":{"id":"DnxTNoW0Bw4Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RA9Ff_18Dr9C"},"source":["## ReRa method: using the similarity based filter -> analysis and selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPWncUAXtB8M"},"outputs":[],"source":["# support function to find the median of the values in a column\n","def find_median_less_than_one(df, col_name):\n","    # Get only the values in the column that are less than 1\n","    values = df[df[col_name] < 1][col_name]\n","    # Compute the median of the values\n","    median = values.median()\n","    return median"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7Dph6ngjKiZ"},"outputs":[],"source":["# support function to find the waste (difference between max median and min median local)\n","def find_deviation_value(dfs, col_name):\n","  median_values = []\n","  for df in dfs:\n","    m =  find_median_less_than_one(df, col_name)\n","    median_values.append(m)\n","  return max(median_values) - min(median_values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YwQuLwrjfzwg"},"outputs":[],"source":["def sbf_analysis(X, Y, additional_link: bool=False, link_mask= None ):\n","  # computing the correlation matrix with pearson correlation from the train set with 49k features \n","  ##### current issue -> ram crashes because computation power is not enough -> reduced to 30k\n","  pc_global = X.corr()\n","  \n","  # checking the scores in the pearson correlation\n","  print(pc_global.describe())\n","  # more information about the distribution of the correlations\n","  # print(pc_global.describe())\n","  # to display the correlation matrix let's plot and show them with a heatmap\n","  '''sb.heatmap(pearson_corr, \n","            xticklabels=pearson_corr.columns,\n","            yticklabels=pearson_corr.columns,\n","            cmap='RdBu_r',\n","            annot=True,\n","            linewidth=0.5)\n","  '''\n","\n","  # find median after removing values equal to 1 or duplicated ones \n","  values = pc_global.values\n","  # get only the vlaues under the diagonal (since simmetric matrix with duplicated values) to compute the global stats\n","  lower_triangular = values[np.tril_indices(values.shape[0], -1)]\n","  flatten = lower_triangular.flatten()\n","  flatten_df = pd.DataFrame(flatten)\n","  flatten_df = flatten_df[flatten_df <1]\n","  # compute global median and save it\n","  global_median = np.median(flatten_df)\n","  print(\"Global median:\", global_median)\n","\n","  pc_global[ pc_global ==1] =  0\n","\n","  print(\"Per class correlation with pearson: \\n\\n\")\n","\n","  local_medians_dic = {}\n","  local_pcs = {}\n","  # for each class in the classes available\n","  for name_class in Y.unique():\n","    print(name_class)\n","    # find the samples from the train assigned to that class\n","    sample_per_class = Y[Y==name_class]\n","    print(\"Samples with label:\", len(sample_per_class))\n","    # choose the corresponding X assigned to the samples with as label the current class\n","    X_class = X.loc[sample_per_class.index]\n","    print(X_class.shape)\n","    # compute correlation matrix only for those samples\n","    class_corr = X_class.corr()\n","    # print(\"Correlation of class \\n\", class_corr)\n","\n","    values = class_corr.values\n","    lower_triangular = values[np.tril_indices(values.shape[0], -1)]\n","    flatten = lower_triangular.flatten()\n","    flatten_df = pd.DataFrame(flatten)\n","    flatten_df = flatten_df[flatten_df <1]\n","    median_local = np.median(flatten_df)\n","    print(\"Local median:\", median_local)\n","    \n","    class_corr[ class_corr ==1] =  0\n","    # saving in two dictionaries the information for the next steps of filtering\n","    # which are: pearson correlation matrices (complete) for only samples of each class\n","    # local median values for each of these \"LOCAL\" pearson correlation matrices\n","    local_pcs[name_class] = class_corr\n","    local_medians_dic[name_class]= median_local\n","  \n","  print(local_medians_dic)\n","\n","  # now I have the global variables: class_corr which is the matrix with correlations and median_global which is the global median threshold\n","  # and the local variables which are the matrix of correlation with samples of each class and local median threshold for each one of them\n","\n","  # Initialize array temp\n","  temp = []\n","  i = 0 # counter to check loop status\n","  # Loop through each column in matrix a\n","  for col in pc_global.columns:\n","\n","      print(\"current feature: \", col, \" we are at the feature n.\", i)\n","      i += 1\n","      # Check if all values in the column are less than median_a\n","      if all(pc_global[col] < global_median):\n","          print(col, \"added to temp array\")\n","          temp.append(col)\n","      else:\n","          # Find rows where values in the column are greater than or equal to the threshold\n","          # these means that these two features are similar and the scores have to be checked locally\n","          row_feats = pc_global[col][pc_global[col] >=  global_median].index.tolist() \n","\n","          for row_feat in row_feats:\n","             # assuimption: the two features are \"also\" locally similar \n","              not_locally_similar = False\n","              # Check if all values in the corresponding columns of local matrices are less than their respective medians\n","              for c_name in local_pcs.keys():\n","                local_pc = local_pcs[c_name]\n","                local_median = local_medians_dic[c_name]\n","                if local_pc[col][row_feat] < local_median: # if all(local_pc[col] < local_median):\n","                  # if all values in the column of the local pearson correlation matrix are under the local threshold we can add both features (row_feat and col) in the temp\n","                  not_locally_similar = True\n","                  break\n","              \n","              if not_locally_similar:\n","                # print(col, row_feat, \" have been added to temp since locally not similar\")\n","                temp.append(col)\n","                temp.append(row_feat)\n","              else:\n","                # print(\"Choosing by looking at higher waste between two features\")\n","                dev_col = find_deviation_value(list(local_pcs.values()), col)\n","                dev_row = find_deviation_value(list(local_pcs.values()), row_feat)\n","                # for the final choice of the feature two keep, looking at the maximum waste for each of the features and choosing the wider one\n","                if dev_col > dev_row:\n","                  temp.append(col)\n","                  # removing all values from temp that correspond to the feature with less waste\n","                  temp = list(filter(lambda a: a != row_feat, temp))\n","                else:\n","                  temp.append(row_feat)\n","                  temp = list(filter(lambda a: a != col, temp))\n","\n","  print(temp)\n","  # removing duplicates\n","  temp_nodup = list(OrderedDict.fromkeys(temp))\n","  return temp_nodup"]},{"cell_type":"markdown","metadata":{"id":"DO6fQsIbCIro"},"source":["### Feature Space with ReRa applied on PAM50-log2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50zaI1YTCf7s"},"outputs":[],"source":["# output of the sbf analysis will be the list of filtered features\n","sbf_pam =  sbf_analysis(X_train_pam_log2,  Y_train_pam_log2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZ6geOUh4HKP"},"outputs":[],"source":["from collections import OrderedDict\n","sbf_nodup = list(OrderedDict.fromkeys(sbf_pam))\n","len(sbf_nodup)\n","\n","for i in sbf_nodup:\n","  if i in X_train_pam_log2.columns:\n","    # print(i)\n","    x = 0\n","  else:\n","    print(i, \"Not in ---> problem\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673811266117,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"guVo9ETbCf7y","outputId":"e6407c4e-537c-493f-ac6f-c63bac574cc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the new train dataset (410, 129)\n","Shape of the new test dataset (127, 129)\n"]}],"source":["selected_col_names = sbf_pam\n","# New x train dataset with only the selected features\n","X_train_pam_sbf = X_train_49kfs[selected_col_names]\n","print(\"Shape of the new train dataset\", X_train_pam_sbf.shape)\n","\n","test_selected_col_names = sbf_pam\n","# New x test dataset with only the selected features\n","X_test_pam_sbf = X_test_49kfs[selected_col_names]\n","print(\"Shape of the new test dataset\",X_test_pam_sbf.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D76DuAnF7Oap"},"outputs":[],"source":["# Uncomment to save the current feature space\n","# pd.DataFrame(selected_col_names).to_csv(path+\"/isoformsfs/sbf_pam.csv\")"]},{"cell_type":"markdown","metadata":{"id":"EZfXbztmCNW_"},"source":["### Feature Space with ReRa applied on LIMMA50 log2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujIrKXGjCkoT"},"outputs":[],"source":["# output of the sbf_analysis will be the lsit of selected features \n","sbf_limma = sbf_analysis(X_train_limma_log2,  Y_train_limma_log2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":691,"status":"ok","timestamp":1673811794494,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"Ne5EROgfCkoU","outputId":"b09095c0-c44e-43aa-db12-424b3a3e7c00"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the new train dataset (410, 533)\n","Shape of the new test dataset (127, 533)\n"]}],"source":["selected_col_names = sbf_limma\n","X_train_limma_sbf = X_train_49kfs[selected_col_names]\n","print(\"Shape of the new train dataset\", X_train_limma_sbf.shape)\n","\n","test_selected_col_names = sbf_limma\n","X_test_limma_sbf = X_test_49kfs[selected_col_names]\n","print(\"Shape of the new test dataset\",X_test_limma_sbf.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltw5UaMO7YNi"},"outputs":[],"source":["# Uncomment to save the current feature space\n","# pd.DataFrame(selected_col_names).to_csv(path+\"/isoformsfs/sbf_limma.csv\")"]},{"cell_type":"markdown","metadata":{"id":"O_EXQAEwCQNn"},"source":["### FS with ReRa applied on Fisher Score log2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QF9o4iiPCjdr"},"outputs":[],"source":["# The code for the actual generation and selection is commented \n","# sbf_fisher = sbf_analysis(X_train_fisher,  Y_train_fisher)\n","\n","# Load the previously saved and generated feature space with the current method\n","sbf_fisher = pd.read_csv(path+\"/isoformsfs/sbf_fisher_th97.csv\", index_col=0,skiprows=1, names=['isoform_id'])\n","sbf_fisher = sbf_fisher['isoform_id'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1673830987057,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"nGZoWtnaCjds","outputId":"14d27f09-7deb-4da6-dc7f-ca02111788f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["(410, 1208)\n","(127, 1208)\n"]}],"source":["selected_col_names = sbf_fisher\n","X_train_fisher_sbf = X_train_49kfs[selected_col_names]\n","print(X_train_fisher_sbf.shape)\n","\n","test_selected_col_names =sbf_fisher\n","X_test_fisher_sbf = X_test_49kfs[selected_col_names]\n","print(X_test_fisher_sbf.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMME6kTk_QU8"},"outputs":[],"source":["# Uncomment to save the current feature space\n","# pd.DataFrame(sbf_fisher).to_csv(path+\"/isoformsfs/sbf_fisher_th97.csv\")"]},{"cell_type":"markdown","metadata":{"id":"1Id65yB5CTOQ"},"source":["### Feature Space with SBF on Mutual Info log2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QtkkeEsTBRfb"},"outputs":[],"source":["# The code for the actual generation and selection is commented \n","# output will be the list of selected features\n","# sbf_mi =  sbf_analysis(X_train_mi,  Y_train_mi)\n","\n","# Load the previously saved and generated feature space with the current method\n","sbf_mi= pd.read_csv(path+\"/isoformsfs/sbf_mi_th97.csv\", index_col=0,skiprows=1, names=['isoform_id'])\n","sbf_mi = sbf_mi['isoform_id'].tolist()\n","len(sbf_mi)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1673876530699,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"whWTWO3QFgfd","outputId":"dc8e1ba8-9322-4446-cd9b-098b107e0dc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the new train dataset (410, 1264)\n","Shape of the new test dataset (127, 1264)\n"]}],"source":["selected_col_names =sbf_mi\n","X_train_mi_sbf = X_train_49kfs[selected_col_names]\n","print(\"Shape of the new train dataset\", X_train_mi_sbf.shape)\n","\n","test_selected_col_names = sbf_mi\n","X_test_mi_sbf = X_test_49kfs[selected_col_names]\n","print(\"Shape of the new test dataset\",X_test_mi_sbf.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nvpKSKx__bus"},"outputs":[],"source":["# Uncomment to save the current feature space\n","# pd.DataFrame(sbf_mi).to_csv(path+\"/isoformsfs/sbf_mi_th97.csv\")"]},{"cell_type":"markdown","metadata":{"id":"PwcS7sUdR5dF"},"source":["### MRMR Feature spaces"]},{"cell_type":"markdown","source":["mrmr 500 size"],"metadata":{"id":"afzKvT7fBKU7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"i5q6Bmuf6M78"},"outputs":[],"source":["# Load the previously saved and generated feature space with the current method\n","selected_feat = pd.read_csv(path+\"/isoformsfs/mrmr500_from12k.csv\", index_col=0,skiprows=1, names=['isoform_id'])\n","selected_feat = selected_feat['isoform_id'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1674774579720,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"oRIa5hqv6Knh","outputId":"d39b5153-c787-4008-e0c9-cac4dd17cce1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(410, 500) (127, 500)\n"]}],"source":["X_train_mrmr_500 = X_train_49kfs[selected_feat].copy()\n","Y_train_mrmr = Y_train_49kfs\n","\n","X_test_mrmr_500 = X_test_49kfs[selected_feat].copy()\n","Y_test_mrmr = Y_test_49kfs\n","print(X_train_mrmr_500.shape, X_test_mrmr_500.shape)"]},{"cell_type":"markdown","metadata":{"id":"C12chYCOR9uD"},"source":["mrmr 750 size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XnefTItR33Q"},"outputs":[],"source":["# Load the previously saved and generated feature space with the current method\n","selected_feat = pd.read_csv(path+\"/isoformsfs/mrmr750_from12kfs.csv\", index_col=0,skiprows=1, names=['gene_id'])\n","selected_feat = selected_feat['gene_id'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1674773752264,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"Y6w5vwfuR33Q","outputId":"fe56ea85-012a-452b-f293-492fd5e87cae"},"outputs":[{"name":"stdout","output_type":"stream","text":["(410, 250) (127, 250)\n"]}],"source":["X_train_mrmr_750 = X_train_49kfs[selected_feat].copy()\n","Y_train_mrmr = Y_train_49kfs\n","\n","X_test_mrmr_750 = X_test_49kfs[selected_feat].copy()\n","Y_test_mrmr = Y_test_49kfs\n","print(X_train_mrmr_750.shape, X_test_mrmr_750.shape)"]},{"cell_type":"markdown","metadata":{"id":"-8F6fcC9R_tb"},"source":["mrmr 1000 size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJcwF2GjR4Rr"},"outputs":[],"source":["# Load the previously saved and generated feature space with the current method\n","selected_feat = pd.read_csv(path+\"/isoformsfs/mrmr1000_from12k.csv\", index_col=0,skiprows=1, names=['isoform_id'])\n","selected_feat = selected_feat['isoform_id'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":250,"status":"ok","timestamp":1674774706515,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"_jTBXtxIR4Rr","outputId":"57c84b7b-6183-4e09-a49d-fe7783ccce3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["(410, 1000) (127, 1000)\n"]}],"source":["X_train_mrmr_1000 = X_train_49kfs[selected_feat].copy()\n","Y_train_mrmr = Y_train_49kfs\n","\n","X_test_mrmr_1000 = X_test_49kfs[selected_feat].copy()\n","Y_test_mrmr = Y_test_49kfs\n","print(X_train_mrmr_1000.shape, X_test_mrmr_1000.shape)"]},{"cell_type":"markdown","metadata":{"id":"hS8speNhmNy4"},"source":["### Model training, evaluation and saving of results\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6pLIoMgkXOZ"},"outputs":[],"source":["def write_results(results, final_path, name_file):\n","      '''\n","      Function to write results metrics and confing into a csv file with as name the current date\n","      '''\n","      # datetime object containing current date and time\n","      now = datetime.now()\n","      dt_string = now.strftime(\"%d%m%Y%H%M%S\")\n","      dt = now.strftime(\"%d%m%Y\")\n","\n","      if not os.path.exists(results_path+final_path+dt+'/'):\n","        os.mkdir(results_path+final_path+dt+'/')\n","        \n","      df = pd.DataFrame(results)\n","      df.to_csv(results_path+final_path+dt+'/'+name_file+dt_string+\".csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GM9h4lt8kf3L"},"outputs":[],"source":["def training_and_saving_after_cv_and_single_split(which_ds, X_train, Y_train,X_test, Y_test, scores, param_values, model):\n","  '''\n","  This function computes the grid search on the parameter space give and on the model and dataset; then it \n","  trains again using the top configuration found, evaluates on the test set and saves the results\n","  '''\n","  C = []\n","  l1_ratio = []\n","  cv_best = []\n","  score_test_balanced_accuracy = []\n","  score_test_accuracy = []\n","  precision = []\n","  recall = []\n","  f1=[]\n","\n","  for index, score in enumerate(scores):\n","      # -------RESULTS in CROSS_VALIDATION-----------\n","      print(\"Tuning hyper-parameters for %s\" % score)\n","      # Fit and hyperparameter search\n","      selected_model = GridSearchCV(model(), param_values, scoring=score, cv=10)\n","      selected_model.fit(X_train, Y_train)\n","      # found best model and fit on training\n","      print(\"Parameter setting that gave the best results on the hold out data: \",  selected_model.best_params_)\n","      print(\"Mean cross-validated score of the best_estimator found, mean, std dev: \",  selected_model.best_score_, selected_model.cv_results_['mean_test_score'], selected_model.cv_results_['std_test_score'] )\n","\n","      # save top config and score from grid search (only accuracy or balanced accuracy)\n","      # evaltype datasetdetails modelname parameters balancedaccuracy\n","      dic_result = {}\n","      dic_result['eval_type']= ['GRID SEARCH RESULTS']\n","      dic_result['dataset_details']= [which_ds]\n","      dic_result['model_name']=  [model.__name__ ]\n","      dic_result['top_parameters']= [str(selected_model.best_params_)]\n","      dic_result['name_score']= [score]\n","      dic_result['best_score'] = [selected_model.best_score_]\n","      dic_result['mean_test_score'] = [selected_model.best_score_]\n","      index, = np.where(selected_model.cv_results_['mean_test_score']==selected_model.best_score_)\n","      dic_result['std_test_score'] =selected_model.cv_results_['std_test_score'][index[0]]\n","\n","      df_result = pd.DataFrame.from_dict(dic_result)\n","      print('Grid search results: ', df_result)\n","      write_results(df_result,model.__name__ +'/', 'cv_on_'+score)\n","\n","      # use top config and trained model for evaluation on test\n","      y_true, y_pred = Y_test, selected_model.predict(X_test)\n","\n","      # save results from test\n","      # evaltype datasetdetails modelname parameters balacc accc prec rec f1\n","      dic_result = {}\n","      dic_result['eval_type']= ['TEST GRID SEARCH RESULTS']\n","      dic_result['dataset_details']= [which_ds]\n","      dic_result['model_name']=  [model.__name__ ]\n","      dic_result['top_parameters']= [str(selected_model.best_params_)]\n","      dic_result['balanced_accuracy'] = [round(balanced_accuracy_score(y_true, y_pred), 3)]\n","      dic_result['accuracy'] = [round(accuracy_score(y_true, y_pred), 3)]\n","      dic_result['precision'] = [round(precision_score(y_true, y_pred, average=\"macro\"), 3)]\n","      dic_result['recall'] = [round(recall_score(y_true, y_pred, average=\"macro\"), 3)]\n","      dic_result['f1_macro'] = [round(f1_score(y_true, y_pred, average=\"macro\"),3)]\n","      dic_result['f1_micro'] = [round(f1_score(y_true, y_pred, average=\"micro\"),3)]\n","\n","      df_result = pd.DataFrame.from_dict(dic_result)\n","      print('Grid search results on test eval: ', df_result)\n","      # not saved anymore because the results are the same as creating new model and performing eval on test set\n","      # it was initiially introduced for verification\n","      # write_results(df_result,model.__name__ +'/', 'testcv_on_'+score) \n","\n","      # create new model with top convig and evaluate for verification\n","      check_model = model(**selected_model.best_params_)\n","      check_model.fit(X_train, Y_train)\n","      \n","      y_true, y_pred = Y_test, check_model.predict(X_test)\n","\n","      # save again the scores\n","      dic_result = {}\n","      dic_result['eval_type']= ['TEST GRID SEARCH RESULTS']\n","      dic_result['dataset_details']= [which_ds]\n","      dic_result['model_name']=  [model.__name__ ]\n","      dic_result['top_parameters']= [str(selected_model.best_params_)]\n","      dic_result['balanced_accuracy'] = [round(balanced_accuracy_score(y_true, y_pred), 3)]\n","      dic_result['accuracy'] = [round(accuracy_score(y_true, y_pred), 3)]\n","      dic_result['precision'] = [round(precision_score(y_true, y_pred, average=\"macro\"), 3)]\n","      dic_result['recall'] = [round(recall_score(y_true, y_pred, average=\"macro\"), 3)]\n","      dic_result['f1_macro'] = [round(f1_score(y_true, y_pred, average=\"macro\"),3)]\n","      dic_result['f1_micro'] = [round(f1_score(y_true, y_pred, average=\"micro\"),3)]\n","\n","      df_result = pd.DataFrame.from_dict(dic_result)\n","      print('Results on test eval: ', df_result)\n","      write_results(df_result,model.__name__ +'/', 'test_on_'+score)"]},{"cell_type":"markdown","metadata":{"id":"aT8xxZKCAi0l"},"source":["### Training, Tuning and Evaluating Models section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t73Zit9ZAmuO"},"outputs":[],"source":["# for each dataset\n","# for each model\n","# create all parameters and other details to pass to the fun\n","# run training and saving function "]},{"cell_type":"markdown","metadata":{"id":"7TTKj6F5Qe5_"},"source":["Parameters spaces definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bXLbBMztKqR"},"outputs":[],"source":["scores = [ \"balanced_accuracy\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1675178521058,"user":{"displayName":"Arianna Galzerano","userId":"03527604948335389522"},"user_tz":-60},"id":"JJC2B6SJ9u-G","outputId":"427b1826-1f5e-4cd2-81e0-ac0952ee91e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["[{'multi_class': ['ovr'], 'penalty': ['elasticnet'], 'solver': ['saga'], 'max_iter': [1000], 'C': [0.1, 0.01, 0.001], 'l1_ratio': [0.1, 0.01, 0.001, 0.005]}]\n","[{'kernel': ['poly'], 'degree': [1, 2, 3], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100], 'max_iter': [1000], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n","[{'min_samples_split': [2, 5, 10], 'max_depth': [100], 'max_features': ['sqrt'], 'min_samples_leaf': [1, 2, 4], 'n_estimators': [150, 200, 500, 750]}]\n","[{'penalty': ['l1', 'l2'], 'max_iter': [1000], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n"]}],"source":["# Configuration of parameters and name\n","\n","# GridSearch attributes\n","# Set the parameters by cross-validation\n","#'l1_ratio':[0.5], 'solver': ['saga'], 'penalty':['elasticnet']\n","logreg_tuned_parameters = [{\n","    'multi_class':  ['ovr'],\n","    'penalty':['elasticnet'],\n","    'solver': ['saga'], \n","    'max_iter':[1000], \n","    'C':  [ 0.1, 0.01, 0.001], #[10 ** i for i in range(-2,1)],\n","    'l1_ratio': [ 0.1, 0.01, 0.001, 0.005] #[10 ** i for i in range(-2,1)] #'l1_ratio':[0.5]}]\n","    }]\n","\n","rf_parameters= [{\n","    'min_samples_split': [2,5,10],\n","    'max_depth': [ 100],\n","    'max_features': [ 'sqrt'],\n","    'min_samples_leaf': [1, 2, 4],\n","    'n_estimators': [150, 200, 500, 750]\n","    }]\n","\n","lin_svc_tuned_parameters = [{\n","    #'kernel':['linear'],  \n","    # 'degree': [1, 2, 3], # 1 for linear, 2 for polynomial\n","    'penalty' : ['l1', 'l2'],\n","    'max_iter':[2000], \n","    'C': [10 ** i for i in range(-3,3)]\n","    }]\n","\n","\n","svc_tuned_parameters = [{\n","    'kernel':['poly'],  \n","    'degree': [1, 2, 3], # 1 for linear, 2 for polynomial\n","    'gamma': [10 ** i for i in range(-3,3)],\n","    'max_iter':[2000], \n","    'C': [10 ** i for i in range(-3,3)]}]\n","\n","print(logreg_tuned_parameters)\n","print(svc_tuned_parameters)\n","print(rf_parameters)\n","print(lin_svc_tuned_parameters)"]},{"cell_type":"markdown","metadata":{"id":"fDg0ZS7mlRcZ"},"source":["### Running experiments section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cY_XwYQikJ4u"},"outputs":[],"source":["for i in range(1,10):\n","    # EVALUATION with LOGISTIC REGRESSION\n","    training_and_saving_after_cv_and_single_split('random_'+str(i), X_train_randoms[i], Y_train_random, X_test_randoms[i], Y_test_random, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","    # EVALUATION with SVC\n","    training_and_saving_after_cv_and_single_split('random_'+str(i),  X_train_randoms[i], Y_train_random, X_test_randoms[i], Y_test_random, scores, svc_tuned_parameters, SVC)\n","\n","    # EVALUATION with Linear SVC\n","    training_and_saving_after_cv_and_single_split('random_'+str(i), X_train_randoms[i], Y_train_random, X_test_randoms[i], Y_test_random, scores,  lin_svc_tuned_parameters, LinearSVC)\n","\n","    # dataset 4\n","    training_and_saving_after_cv_and_single_split('random_'+str(i),  X_train_randoms[i], Y_train_random, X_test_randoms[i], Y_test_random, scores, rf_parameters,model=RandomForestClassifier)\n"]},{"cell_type":"markdown","metadata":{"id":"MnomFzW2lhlf"},"source":[" FIsher feature space"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQVYihfqlg5i"},"outputs":[],"source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('mrmr_from12k', X_train_fisher, Y_train_fisher, X_test_fisher, Y_test_fisher, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('mrmr_from12k', X_train_fisher, Y_train_fisher, X_test_fisher, Y_test_fisher, scores, svc_tuned_parameters, SVC)\n","\n","# EVALUATION with Linear SVC\n","training_and_saving_after_cv_and_single_split('mrmr_from12k', X_train_fisher, Y_train_fisher, X_test_fisher, Y_test_fisher, scores,  lin_svc_tuned_parameters, LinearSVC)\n","\n","# dataset 4\n","training_and_saving_after_cv_and_single_split('mrmr_from12k', X_train_fisher, Y_train_fisher, X_test_fisher, Y_test_fisher, scores, rf_parameters,model=RandomForestClassifier)"]},{"cell_type":"markdown","metadata":{"id":"Mp372Yz5lkie"},"source":["Mutual information space\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"F32asGealam-"},"outputs":[],"source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('mi_fs_97', X_train_mi, Y_train_mi, X_test_mi, Y_test_mi, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('mi_fs_97', X_train_mi, Y_train_mi, X_test_mi, Y_test_mi, scores, svc_tuned_parameters, SVC)\n","\n","# EVALUATION with Linear SVC\n","training_and_saving_after_cv_and_single_split('mi_fs_97', X_train_mi, Y_train_mi, X_test_mi, Y_test_mi, scores,  lin_svc_tuned_parameters, LinearSVC)\n","\n","# dataset 4\n","training_and_saving_after_cv_and_single_split('mi_fs_97', X_train_mi, Y_train_mi, X_test_mi, Y_test_mi, scores, rf_parameters,model=RandomForestClassifier)"]},{"cell_type":"markdown","metadata":{"id":"FnequLkAlnFp"},"source":["## ReRa tuning and testing"]},{"cell_type":"markdown","metadata":{"id":"eSVbOMiSDDo-"},"source":["pam"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NS4eEq69lqLt"},"outputs":[],"source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('sbf_pam_fs', X_train_pam_sbf, Y_train_mi, X_test_pam_sbf, Y_test_mi, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('sbf_pam_fs', X_train_pam_sbf, Y_train_mi, X_test_pam_sbf, Y_test_mi, scores, svc_tuned_parameters, SVC)\n","\n","# dataset random forest\n","training_and_saving_after_cv_and_single_split('sbf_pam_fs', X_train_pam_sbf, Y_train_mi, X_test_pam_sbf, Y_test_mi, scores, rf_parameters,model=RandomForestClassifier)\n","\n","\n","# EVALUATION with Linear SVC\n","training_and_saving_after_cv_and_single_split('sbf_pam_fs', X_train_pam_sbf, Y_train_mi, X_test_pam_sbf, Y_test_mi, scores, lin_svc_tuned_parameters, LinearSVC)\n"]},{"cell_type":"markdown","metadata":{"id":"T2q2a0CvDFZ3"},"source":["limma"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2VrfW80IDC_Y"},"outputs":[],"source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('sbf_limma_fs', X_train_limma_sbf, Y_train_mi, X_test_limma_sbf, Y_test_mi, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('sbf_limma_fs', X_train_limma_sbf, Y_train_mi, X_test_limma_sbf, Y_test_mi, scores, svc_tuned_parameters, SVC)\n","\n","# dataset random forest\n","training_and_saving_after_cv_and_single_split('sbf_limma_fs', X_train_limma_sbf, Y_train_mi, X_test_limma_sbf, Y_test_mi, scores, rf_parameters,model=RandomForestClassifier)\n","\n","# EVALUATION with Linear SVC\n","training_and_saving_after_cv_and_single_split('sbf_limma_fs', X_train_limma_sbf, Y_train_mi, X_test_limma_sbf, Y_test_mi, scores, lin_svc_tuned_parameters, LinearSVC)"]},{"cell_type":"markdown","metadata":{"id":"kdAz_MISDGmO"},"source":["fisher"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"egF5gK7zDJGp"},"outputs":[],"source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('sbf_fisher_fs_97', X_train_fisher_sbf, Y_train_mi, X_test_fisher_sbf, Y_test_mi, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('sbf_fisher_fs_97', X_train_fisher_sbf, Y_train_mi, X_test_fisher_sbf, Y_test_mi, scores, svc_tuned_parameters, SVC)\n","\n","# dataset random forest\n","training_and_saving_after_cv_and_single_split('sbf_fisher_fs_97', X_train_fisher_sbf, Y_train_mi, X_test_fisher_sbf, Y_test_mi, scores, rf_parameters,model=RandomForestClassifier)\n","\n","# EVALUATION with Linear SVC\n","training_and_saving_after_cv_and_single_split('sbf_fisher_fs_97', X_train_fisher_sbf, Y_train_mi, X_test_fisher_sbf, Y_test_mi, scores, lin_svc_tuned_parameters, LinearSVC)\n"]},{"cell_type":"markdown","metadata":{"id":"1Ez3t2A7DH0D"},"source":["mutual info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AF3xy_3_DJvc"},"outputs":[],"source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('sbf_mutualinfo_fs_97', X_train_mi_sbf, Y_train_mi, X_test_mi_sbf, Y_test_mi, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('sbf_mutualinfo_fs_97', X_train_mi_sbf, Y_train_mi, X_test_mi_sbf, Y_test_mi, scores, svc_tuned_parameters, SVC)\n","\n","# dataset random forest\n","training_and_saving_after_cv_and_single_split('sbf_mutualinfo_fs_97', X_train_mi_sbf, Y_train_mi, X_test_mi_sbf, Y_test_mi, scores, rf_parameters,model=RandomForestClassifier)\n","\n","# EVALUATION with Linear SVC\n","training_and_saving_after_cv_and_single_split('sbf_mutualinfo_fs_97', X_train_mi_sbf, Y_train_mi, X_test_mi_sbf, Y_test_mi, scores, lin_svc_tuned_parameters, LinearSVC)"]},{"cell_type":"markdown","metadata":{"id":"N3v0EUifTM0R"},"source":["# mrmr\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjvnG5lLW1ip"},"outputs":[],"source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('mrmr_500_from12k', X_train_mrmr_500, Y_train_mrmr, X_test_mrmr_500, Y_test_mrmr, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('mrmr_500_from12k', X_train_mrmr_500, Y_train_mrmr, X_test_mrmr_500, Y_test_mrmr, scores, svc_tuned_parameters, SVC)\n","\n","# EVALUATION with Linear SVC\n","training_and_saving_after_cv_and_single_split('mrmr_500_from12k', X_train_mrmr_500, Y_train_mrmr, X_test_mrmr_500, Y_test_mrmr, scores,  lin_svc_tuned_parameters, LinearSVC)\n","\n","# dataset 4\n","training_and_saving_after_cv_and_single_split('mrmr_500_from12k', X_train_mrmr_500, Y_train_mrmr, X_test_mrmr_500, Y_test_mrmr, scores, rf_parameters,model=RandomForestClassifier)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5QUMb4VgT9f_"},"outputs":[],"source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('mrmr_750_from12k', X_train_mrmr_750, Y_train_mrmr, X_test_mrmr_750, Y_test_mrmr, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('mrmr_750_from12k', X_train_mrmr_750, Y_train_mrmr, X_test_mrmr_750, Y_test_mrmr, scores, svc_tuned_parameters, SVC)\n","\n","# EVALUATION with Linear SVC\n","training_and_saving_after_cv_and_single_split('mrmr_750_from12k', X_train_mrmr_750, Y_train_mrmr, X_test_mrmr_750, Y_test_mrmr, scores,  lin_svc_tuned_parameters, LinearSVC)\n","\n","# dataset 4\n","training_and_saving_after_cv_and_single_split('mrmr_750_from12k', X_train_mrmr_750, Y_train_mrmr, X_test_mrmr_750, Y_test_mrmr, scores, rf_parameters,model=RandomForestClassifier)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y03aCDm4UEyG"},"outputs":[],"source":["# EVALUATION with LOGISTIC REGRESSION\n","training_and_saving_after_cv_and_single_split('mrmr_1000_from12k', X_train_mrmr_1000, Y_train_mrmr, X_test_mrmr_1000, Y_test_mrmr, scores, logreg_tuned_parameters, LogisticRegression)\n","\n","# EVALUATION with SVC\n","training_and_saving_after_cv_and_single_split('mrmr_1000_from12k', X_train_mrmr_1000, Y_train_mrmr, X_test_mrmr_1000, Y_test_mrmr, scores, svc_tuned_parameters, SVC)\n","\n","# EVALUATION with Linear SVC\n","training_and_saving_after_cv_and_single_split('mrmr_1000_from12k', X_train_mrmr_1000, Y_train_mrmr, X_test_mrmr_1000, Y_test_mrmr, scores,  lin_svc_tuned_parameters, LinearSVC)\n","\n","# dataset 4\n","training_and_saving_after_cv_and_single_split('mrmr_1000_from12k', X_train_mrmr_1000, Y_train_mrmr, X_test_mrmr_1000, Y_test_mrmr, scores, rf_parameters,model=RandomForestClassifier)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}